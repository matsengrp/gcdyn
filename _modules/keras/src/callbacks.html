

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>keras.src.callbacks &#8212; gcdyn  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/keras/src/callbacks';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="gcdyn  documentation - Home"/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt="gcdyn  documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cite.html">Citing <code class="docutils literal notranslate"><span class="pre">gcdyn</span></code></a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/bdms_replay.html">Germinal center replay modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/bdms_inhomogeneous.html">Inhomogeneous processes</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Command line tools</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../argparse.html">Named Arguments</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api.html">Modules</a><input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/gcdyn.bdms.html">gcdyn.bdms</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.bdms.sample_trees.html">gcdyn.bdms.sample_trees</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.bdms.TreeNode.html">gcdyn.bdms.TreeNode</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.html">gcdyn.encode</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.encode_tree.html">gcdyn.encode.encode_tree</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.encode_trees.html">gcdyn.encode.encode_trees</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.pad_trees.html">gcdyn.encode.pad_trees</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.read_trees.html">gcdyn.encode.read_trees</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.scale_tree.html">gcdyn.encode.scale_tree</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.simfn.html">gcdyn.encode.simfn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.trivialize_encodings.html">gcdyn.encode.trivialize_encodings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.write_training_files.html">gcdyn.encode.write_training_files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.encode.write_trees.html">gcdyn.encode.write_trees</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/gcdyn.fitness.html">gcdyn.fitness</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.fitness.Fitness.html">gcdyn.fitness.Fitness</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/gcdyn.gpmap.html">gcdyn.gpmap</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.gpmap.AdditiveGPMap.html">gcdyn.gpmap.AdditiveGPMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.gpmap.ConstantGPMap.html">gcdyn.gpmap.ConstantGPMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.gpmap.GPMap.html">gcdyn.gpmap.GPMap</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/gcdyn.models.html">gcdyn.models</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.models.naive_log_likelihood.html">gcdyn.models.naive_log_likelihood</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.models.stadler_appx_log_likelihood.html">gcdyn.models.stadler_appx_log_likelihood</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.models.stadler_full_log_likelihood.html">gcdyn.models.stadler_full_log_likelihood</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.models.stadler_full_log_likelihood_scipy.html">gcdyn.models.stadler_full_log_likelihood_scipy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.models.BirthDeathModel.html">gcdyn.models.BirthDeathModel</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.html">gcdyn.mutators</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.AttrMutator.html">gcdyn.mutators.AttrMutator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.ContextMutator.html">gcdyn.mutators.ContextMutator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.DiscreteMutator.html">gcdyn.mutators.DiscreteMutator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.GaussianMutator.html">gcdyn.mutators.GaussianMutator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.KdeMutator.html">gcdyn.mutators.KdeMutator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.Mutator.html">gcdyn.mutators.Mutator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.SequenceMutator.html">gcdyn.mutators.SequenceMutator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.SequencePhenotypeMutator.html">gcdyn.mutators.SequencePhenotypeMutator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.mutators.UniformMutator.html">gcdyn.mutators.UniformMutator</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/gcdyn.nn.html">gcdyn.nn</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.nn.BundleMeanLayer.html">gcdyn.nn.BundleMeanLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.nn.Callback.html">gcdyn.nn.Callback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.nn.NeuralNetworkModel.html">gcdyn.nn.NeuralNetworkModel</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.html">gcdyn.poisson</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.set_backend.html">gcdyn.poisson.set_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.ConstantResponse.html">gcdyn.poisson.ConstantResponse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.ExponentialResponse.html">gcdyn.poisson.ExponentialResponse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.HomogeneousResponse.html">gcdyn.poisson.HomogeneousResponse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.ModulatedPhenotypeResponse.html">gcdyn.poisson.ModulatedPhenotypeResponse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.ModulatedRateResponse.html">gcdyn.poisson.ModulatedRateResponse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.PhenotypeResponse.html">gcdyn.poisson.PhenotypeResponse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.PhenotypeTimeResponse.html">gcdyn.poisson.PhenotypeTimeResponse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.Response.html">gcdyn.poisson.Response</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.SequenceContextMutationResponse.html">gcdyn.poisson.SequenceContextMutationResponse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.SigmoidResponse.html">gcdyn.poisson.SigmoidResponse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.poisson.SoftReluResponse.html">gcdyn.poisson.SoftReluResponse</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.html">gcdyn.utils</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.addfn.html">gcdyn.utils.addfn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.arglist_imatches.html">gcdyn.utils.arglist_imatches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.arglist_index.html">gcdyn.utils.arglist_index</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.color.html">gcdyn.utils.color</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.color_mutants.html">gcdyn.utils.color_mutants</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.insert_in_arglist.html">gcdyn.utils.insert_in_arglist</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.is_in_arglist.html">gcdyn.utils.is_in_arglist</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.isclose.html">gcdyn.utils.isclose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.ladderize_tree.html">gcdyn.utils.ladderize_tree</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.limit_procs.html">gcdyn.utils.limit_procs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.make_dl_plots.html">gcdyn.utils.make_dl_plots</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.make_html.html">gcdyn.utils.make_html</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.memory_usage_fraction.html">gcdyn.utils.memory_usage_fraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.mpl_init.html">gcdyn.utils.mpl_init</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.node_contexts.html">gcdyn.utils.node_contexts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.padded_fivemer_contexts_of_paired_sequences.html">gcdyn.utils.padded_fivemer_contexts_of_paired_sequences</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.plot_chosen_params.html">gcdyn.utils.plot_chosen_params</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.plot_phenotype_response.html">gcdyn.utils.plot_phenotype_response</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.plot_responses.html">gcdyn.utils.plot_responses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.plot_tree_slices.html">gcdyn.utils.plot_tree_slices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.random_transition_matrix.html">gcdyn.utils.random_transition_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.remove_from_arglist.html">gcdyn.utils.remove_from_arglist</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.replace_in_arglist.html">gcdyn.utils.replace_in_arglist</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.simple_fivemer_contexts.html">gcdyn.utils.simple_fivemer_contexts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gcdyn.utils.write_leaf_sequences_to_fasta.html">gcdyn.utils.write_leaf_sequences_to_fasta</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Experiments subpackage</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../experiments.html">Modules</a><input checked class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/experiments.replay.html">experiments.replay</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/experiments.replay.NAIVE_SEQUENCE.html">experiments.replay.NAIVE_SEQUENCE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/experiments.replay.CHAIN_2_START_IDX.html">experiments.replay.CHAIN_2_START_IDX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/experiments.replay.dms.html">experiments.replay.dms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/experiments.replay.mutability.html">experiments.replay.mutability</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/experiments.replay.substitution.html">experiments.replay.substitution</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Documentation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../developer.html">Developer tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../todo.html">To-do list</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/matsengrp/gcdyn" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for keras.src.callbacks</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>


<span class="sd">&quot;&quot;&quot;Callbacks: utilities called at certain points during model training.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow.compat.v2</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">keras.src</span> <span class="kn">import</span> <span class="n">backend</span>
<span class="kn">from</span> <span class="nn">keras.src.distribute</span> <span class="kn">import</span> <span class="n">distributed_file_utils</span>
<span class="kn">from</span> <span class="nn">keras.src.distribute</span> <span class="kn">import</span> <span class="n">worker_training_state</span>
<span class="kn">from</span> <span class="nn">keras.src.optimizers</span> <span class="kn">import</span> <span class="n">optimizer</span>
<span class="kn">from</span> <span class="nn">keras.src.optimizers.schedules</span> <span class="kn">import</span> <span class="n">learning_rate_schedule</span>
<span class="kn">from</span> <span class="nn">keras.src.utils</span> <span class="kn">import</span> <span class="n">generic_utils</span>
<span class="kn">from</span> <span class="nn">keras.src.utils</span> <span class="kn">import</span> <span class="n">io_utils</span>
<span class="kn">from</span> <span class="nn">keras.src.utils</span> <span class="kn">import</span> <span class="n">tf_utils</span>
<span class="kn">from</span> <span class="nn">keras.src.utils</span> <span class="kn">import</span> <span class="n">version_utils</span>
<span class="kn">from</span> <span class="nn">keras.src.utils.data_utils</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">keras.src.utils.generic_utils</span> <span class="kn">import</span> <span class="n">Progbar</span>
<span class="kn">from</span> <span class="nn">keras.src.utils.mode_keys</span> <span class="kn">import</span> <span class="n">ModeKeys</span>

<span class="c1"># isort: off</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.platform</span> <span class="kn">import</span> <span class="n">tf_logging</span> <span class="k">as</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="kn">import</span> <span class="n">deprecation</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.tf_export</span> <span class="kn">import</span> <span class="n">keras_export</span>
<span class="kn">from</span> <span class="nn">tensorflow.tools.docs</span> <span class="kn">import</span> <span class="n">doc_controls</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">requests</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">requests</span> <span class="o">=</span> <span class="kc">None</span>


<span class="c1"># Note: `configure_callbacks` is only used in TF1.</span>
<span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span>
    <span class="n">callbacks</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">do_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">count_mode</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configures callbacks for use in various training loops.</span>

<span class="sd">    Args:</span>
<span class="sd">        callbacks: List of Callbacks.</span>
<span class="sd">        model: Model being trained.</span>
<span class="sd">        do_validation: Whether or not validation loop will be run.</span>
<span class="sd">        batch_size: Number of samples per batch.</span>
<span class="sd">        epochs: Number of epoch to train.</span>
<span class="sd">        steps_per_epoch: Number of batches to run per training epoch.</span>
<span class="sd">        samples: Number of training samples.</span>
<span class="sd">        verbose: int, 0 or 1. Keras logging verbosity to pass to ProgbarLogger.</span>
<span class="sd">        count_mode: One of &#39;steps&#39; or &#39;samples&#39;. Per-batch or per-sample count.</span>
<span class="sd">        mode: String. One of ModeKeys.TRAIN, ModeKeys.TEST, or ModeKeys.PREDICT.</span>
<span class="sd">          Which loop mode to configure callbacks for.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Instance of CallbackList used to control all Callbacks.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check if callbacks have already been configured.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">CallbackList</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">callbacks</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">callbacks</span><span class="p">:</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Add additional callbacks during training.</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">History</span><span class="p">()</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">BaseLogger</span><span class="p">()]</span> <span class="o">+</span> <span class="p">(</span><span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[])</span> <span class="o">+</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ProgbarLogger</span><span class="p">(</span><span class="n">count_mode</span><span class="p">))</span>
    <span class="n">callback_list</span> <span class="o">=</span> <span class="n">CallbackList</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span>

    <span class="c1"># Set callback model</span>
    <span class="n">callback_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_get_callback_model</span><span class="p">()</span>
    <span class="n">callback_list</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">callback_model</span><span class="p">)</span>

    <span class="n">set_callback_parameters</span><span class="p">(</span>
        <span class="n">callback_list</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">do_validation</span><span class="o">=</span><span class="n">do_validation</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
        <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">callback_list</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">callback_list</span>


<span class="k">def</span> <span class="nf">set_callback_parameters</span><span class="p">(</span>
    <span class="n">callback_list</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">do_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sets callback parameters.</span>

<span class="sd">    Args:</span>
<span class="sd">        callback_list: CallbackList instance.</span>
<span class="sd">        model: Model being trained.</span>
<span class="sd">        do_validation: Whether or not validation loop will be run.</span>
<span class="sd">        batch_size: Number of samples per batch.</span>
<span class="sd">        epochs: Number of epoch to train.</span>
<span class="sd">        steps_per_epoch: Number of batches to run per training epoch.</span>
<span class="sd">        samples: Number of training samples.</span>
<span class="sd">        verbose: int, 0 or 1. Keras logging verbosity to pass to ProgbarLogger.</span>
<span class="sd">        mode: String. One of ModeKeys.TRAIN, ModeKeys.TEST, or ModeKeys.PREDICT.</span>
<span class="sd">          Which loop mode to configure callbacks for.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">metric_names</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">cbk</span> <span class="ow">in</span> <span class="n">callback_list</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cbk</span><span class="p">,</span> <span class="p">(</span><span class="n">BaseLogger</span><span class="p">,</span> <span class="n">ProgbarLogger</span><span class="p">)):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">metric_names</span><span class="p">:</span>
                <span class="n">metric_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span>
            <span class="n">cbk</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="n">metric_names</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># Exclude `loss`</span>

    <span class="c1"># Set callback parameters</span>
    <span class="n">callback_metrics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># When we have deferred build scenario with iterator input, we will compile</span>
    <span class="c1"># when we standardize first batch of data.</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">!=</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">metric_names</span><span class="p">:</span>
            <span class="n">metric_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span>
        <span class="n">callback_metrics</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">metric_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">do_validation</span><span class="p">:</span>
            <span class="n">callback_metrics</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;val_&quot;</span> <span class="o">+</span> <span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">metric_names</span><span class="p">]</span>
    <span class="n">callback_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
        <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="n">epochs</span><span class="p">,</span>
        <span class="s2">&quot;steps&quot;</span><span class="p">:</span> <span class="n">steps_per_epoch</span><span class="p">,</span>
        <span class="s2">&quot;samples&quot;</span><span class="p">:</span> <span class="n">samples</span><span class="p">,</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="n">verbose</span><span class="p">,</span>
        <span class="s2">&quot;do_validation&quot;</span><span class="p">:</span> <span class="n">do_validation</span><span class="p">,</span>
        <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="n">callback_metrics</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">callback_list</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">callback_params</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_is_generator_like</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Checks if data is a generator, Sequence, or Iterator.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;__next__&quot;</span><span class="p">)</span>
        <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;next&quot;</span><span class="p">)</span>
        <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">Sequence</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">make_logs</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes logs for sending to `on_batch_end` methods.&quot;&quot;&quot;</span>
    <span class="n">metric_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">{</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">}</span> <span class="ow">and</span> <span class="n">metric_names</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metric_names</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
            <span class="n">logs</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;outputs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs</span>
    <span class="k">return</span> <span class="n">logs</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.CallbackList&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CallbackList</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Container abstracting a list of callbacks.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">add_history</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">add_progbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">params</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Container for `Callback` instances.</span>

<span class="sd">        This object wraps a list of `Callback` instances, making it possible</span>
<span class="sd">        to call them all at once via a single endpoint</span>
<span class="sd">        (e.g. `callback_list.on_epoch_end(...)`).</span>

<span class="sd">        Args:</span>
<span class="sd">          callbacks: List of `Callback` instances.</span>
<span class="sd">          add_history: Whether a `History` callback should be added, if one does</span>
<span class="sd">            not already exist in the `callbacks` list.</span>
<span class="sd">          add_progbar: Whether a `ProgbarLogger` callback should be added, if</span>
<span class="sd">            one does not already exist in the `callbacks` list.</span>
<span class="sd">          model: The `Model` these callbacks are used with.</span>
<span class="sd">          **params: If provided, parameters will be passed to each `Callback`</span>
<span class="sd">            via `Callback.set_params`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span> <span class="k">if</span> <span class="n">callbacks</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_default_callbacks</span><span class="p">(</span><span class="n">add_history</span><span class="p">,</span> <span class="n">add_progbar</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">model</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

        <span class="c1"># Performance optimization: determines if batch hooks need to be called.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="s2">&quot;_supports_tf_logs&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_hooks_support_tf_logs</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="s2">&quot;_supports_tf_logs&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span>
            <span class="k">if</span> <span class="n">cb</span><span class="o">.</span><span class="n">_implements_train_batch_hooks</span><span class="p">()</span>
            <span class="ow">or</span> <span class="n">cb</span><span class="o">.</span><span class="n">_implements_test_batch_hooks</span><span class="p">()</span>
            <span class="ow">or</span> <span class="n">cb</span><span class="o">.</span><span class="n">_implements_predict_batch_hooks</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
            <span class="n">cb</span><span class="o">.</span><span class="n">_implements_train_batch_hooks</span><span class="p">()</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_test_batch_hooks</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
            <span class="n">cb</span><span class="o">.</span><span class="n">_implements_test_batch_hooks</span><span class="p">()</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_predict_batch_hooks</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
            <span class="n">cb</span><span class="o">.</span><span class="n">_implements_predict_batch_hooks</span><span class="p">()</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_disallow_batch_hooks_in_ps_strategy</span><span class="p">()</span>

        <span class="c1"># Performance check: Check batch hooks for slowness compared to batch</span>
        <span class="c1"># time.  Only run check for custom callbacks (i.e. not present in this</span>
        <span class="c1"># file).</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
            <span class="n">cbk</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">()</span> <span class="k">for</span> <span class="n">cbk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_batches_for_timing_check</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">_add_default_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">add_history</span><span class="p">,</span> <span class="n">add_progbar</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adds `Callback`s that are always present.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">ProgbarLogger</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span> <span class="o">=</span> <span class="n">cb</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">History</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="n">cb</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">add_history</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="n">History</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">add_progbar</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span> <span class="o">=</span> <span class="n">ProgbarLogger</span><span class="p">(</span><span class="n">count_mode</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_process_logs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">is_batch_hook</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Turns tensors into numpy arrays or Python scalars if necessary.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">logs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">logs</span>
        <span class="k">if</span> <span class="n">is_batch_hook</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_hooks_support_tf_logs</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">logs</span>
        <span class="k">return</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">callback</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_call_batch_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hook</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper function for all batch_{begin | end} methods.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">hook</span> <span class="o">==</span> <span class="s2">&quot;begin&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_begin_hook</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">hook</span> <span class="o">==</span> <span class="s2">&quot;end&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_end_hook</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unrecognized hook: </span><span class="si">{</span><span class="n">hook</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="s1">&#39;Expected values are [&quot;begin&quot;, &quot;end&quot;]&#39;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_call_batch_begin_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper function for `on_*_batch_begin` methods.&quot;&quot;&quot;</span>
        <span class="n">hook_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;on_</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">_batch_begin&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook_helper</span><span class="p">(</span><span class="n">hook_name</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_call_batch_end_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper function for `on_*_batch_end` methods.&quot;&quot;&quot;</span>
        <span class="n">hook_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;on_</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">_batch_end&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span> <span class="ow">and</span> <span class="n">batch</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">batch_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_time</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook_helper</span><span class="p">(</span><span class="n">hook_name</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batches_for_timing_check</span><span class="p">:</span>
            <span class="n">end_hook_name</span> <span class="o">=</span> <span class="n">hook_name</span>
            <span class="n">begin_hook_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;on_</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">_batch_begin&quot;</span>
            <span class="n">avg_batch_time</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span><span class="p">)</span>
            <span class="n">avg_end_hook_time</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">end_hook_name</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">end_hook_name</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">avg_begin_hook_time</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">begin_hook_name</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">begin_hook_name</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="n">threshold_time</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">avg_batch_time</span>
            <span class="n">warning_msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;Callback method `</span><span class="si">{hook}</span><span class="s2">` is slow compared to &quot;</span>
                <span class="s2">&quot;the batch time (batch time: </span><span class="si">{batch_time:.4f}</span><span class="s2">s vs &quot;</span>
                <span class="s2">&quot;`</span><span class="si">{hook}</span><span class="s2">` time: </span><span class="si">{hook_time:.4f}</span><span class="s2">s). Check your callbacks.&quot;</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">avg_begin_hook_time</span> <span class="o">&gt;</span> <span class="n">threshold_time</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="n">warning_msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">hook</span><span class="o">=</span><span class="n">begin_hook_name</span><span class="p">,</span>
                        <span class="n">batch_time</span><span class="o">=</span><span class="n">avg_batch_time</span><span class="p">,</span>
                        <span class="n">hook_time</span><span class="o">=</span><span class="n">avg_begin_hook_time</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">avg_end_hook_time</span> <span class="o">&gt;</span> <span class="n">threshold_time</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="n">warning_msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">hook</span><span class="o">=</span><span class="n">end_hook_name</span><span class="p">,</span>
                        <span class="n">batch_time</span><span class="o">=</span><span class="n">avg_batch_time</span><span class="p">,</span>
                        <span class="n">hook_time</span><span class="o">=</span><span class="n">avg_end_hook_time</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">_call_batch_hook_helper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper function for `on_*_batch_*` methods.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span><span class="p">:</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="n">is_batch_hook</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">hook</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">)</span>
            <span class="n">hook</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">hook_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">hook_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">hook_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_call_begin_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper function for on_{train|test|predict}_begin methods.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_test_begin</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_call_end_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper function for on_{train|test|predict}_end methods.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_test_end</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_predict_end</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s2">&quot;begin&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s2">&quot;end&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_epoch_begin` methods of its callbacks.</span>

<span class="sd">        This function should only be called during TRAIN mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch: Integer, index of epoch.</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">               method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_epoch_end` methods of its callbacks.</span>

<span class="sd">        This function should only be called during TRAIN mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch: Integer, index of epoch.</span>
<span class="sd">            logs: Dict, metric results for this training epoch, and for the</span>
<span class="sd">              validation epoch if validation is performed. Validation result</span>
<span class="sd">              keys are prefixed with `val_`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_train_batch_begin` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict, contains the return value of `model.train_step`.</span>
<span class="sd">              Typically, the values of the `Model`&#39;s metrics are returned.</span>
<span class="sd">              Example: `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s2">&quot;begin&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_train_batch_end` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s2">&quot;end&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_test_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_test_batch_begin` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict, contains the return value of `model.test_step`.</span>
<span class="sd">              Typically, the values of the `Model`&#39;s metrics are returned.</span>
<span class="sd">              Example: `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_test_batch_hooks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="s2">&quot;begin&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_test_batch_end` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_test_batch_hooks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="s2">&quot;end&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_predict_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_predict_batch_begin` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict, contains the return value of `model.predict_step`,</span>
<span class="sd">              it typically returns a dict with a key &#39;outputs&#39; containing</span>
<span class="sd">              the model&#39;s outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_predict_batch_hooks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">,</span> <span class="s2">&quot;begin&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_predict_batch_end` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_predict_batch_hooks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">,</span> <span class="s2">&quot;end&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_train_begin` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently, no data is passed via this argument</span>
<span class="sd">              for this method, but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_train_end` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently, no data is passed via this argument</span>
<span class="sd">              for this method, but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_test_begin` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">on_test_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_test_end` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently, no data is passed via this argument</span>
<span class="sd">              for this method, but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the &#39;on_predict_begin` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">on_predict_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the `on_predict_end` methods of its callbacks.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently, no data is passed via this argument</span>
<span class="sd">              for this method, but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">on_predict_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_disallow_batch_hooks_in_ps_strategy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Error out if batch-level callbacks are passed with PSStrategy.&quot;&quot;&quot;</span>

        <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">get_strategy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span>
            <span class="n">unsupported_callbacks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
                <span class="c1"># These Callbacks can accept RemoteValues directly.</span>
                <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="s2">&quot;_supports_tf_logs&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">cb</span><span class="o">.</span><span class="n">_implements_train_batch_hooks</span><span class="p">()</span>
                    <span class="ow">or</span> <span class="n">cb</span><span class="o">.</span><span class="n">_implements_test_batch_hooks</span><span class="p">()</span>
                    <span class="ow">or</span> <span class="n">cb</span><span class="o">.</span><span class="n">_implements_predict_batch_hooks</span><span class="p">()</span>
                <span class="p">):</span>
                    <span class="n">unsupported_callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cb</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">unsupported_callbacks</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Batch-level `Callback`s are not supported with &quot;</span>
                    <span class="s2">&quot;`ParameterServerStrategy`. Found unsupported &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;callbacks: </span><span class="si">{</span><span class="n">unsupported_callbacks</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_logs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes logs for sending to `on_batch_end` methods.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">logs</span>

        <span class="k">return</span> <span class="n">make_logs</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.Callback&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Callback</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Abstract base class used to build new callbacks.</span>

<span class="sd">    Callbacks can be passed to keras methods such as `fit`, `evaluate`, and</span>
<span class="sd">    `predict` in order to hook into the various stages of the model training and</span>
<span class="sd">    inference lifecycle.</span>

<span class="sd">    To create a custom callback, subclass `keras.callbacks.Callback` and</span>
<span class="sd">    override the method associated with the stage of interest. See</span>
<span class="sd">    https://www.tensorflow.org/guide/keras/custom_callback for more information.</span>

<span class="sd">    Example:</span>

<span class="sd">    &gt;&gt;&gt; training_finished = False</span>
<span class="sd">    &gt;&gt;&gt; class MyCallback(tf.keras.callbacks.Callback):</span>
<span class="sd">    ...   def on_train_end(self, logs=None):</span>
<span class="sd">    ...     global training_finished</span>
<span class="sd">    ...     training_finished = True</span>
<span class="sd">    &gt;&gt;&gt; model = tf.keras.Sequential([</span>
<span class="sd">    ...     tf.keras.layers.Dense(1, input_shape=(1,))])</span>
<span class="sd">    &gt;&gt;&gt; model.compile(loss=&#39;mean_squared_error&#39;)</span>
<span class="sd">    &gt;&gt;&gt; model.fit(tf.constant([[1.0]]), tf.constant([[1.0]]),</span>
<span class="sd">    ...           callbacks=[MyCallback()])</span>
<span class="sd">    &gt;&gt;&gt; assert training_finished == True</span>

<span class="sd">    If you want to use `Callback` objects in a custom training loop:</span>

<span class="sd">    1. You should pack all your callbacks into a single `callbacks.CallbackList`</span>
<span class="sd">       so they can all be called together.</span>
<span class="sd">    2. You will need to manually call all the `on_*` methods at the appropriate</span>
<span class="sd">       locations in your loop. Like this:</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">       callbacks =  tf.keras.callbacks.CallbackList([...])</span>
<span class="sd">       callbacks.append(...)</span>
<span class="sd">       callbacks.on_train_begin(...)</span>
<span class="sd">       for epoch in range(EPOCHS):</span>
<span class="sd">         callbacks.on_epoch_begin(epoch)</span>
<span class="sd">         for i, data in dataset.enumerate():</span>
<span class="sd">           callbacks.on_train_batch_begin(i)</span>
<span class="sd">           batch_logs = model.train_step(data)</span>
<span class="sd">           callbacks.on_train_batch_end(i, batch_logs)</span>
<span class="sd">         epoch_logs = ...</span>
<span class="sd">         callbacks.on_epoch_end(epoch, epoch_logs)</span>
<span class="sd">       final_logs=...</span>
<span class="sd">       callbacks.on_train_end(final_logs)</span>
<span class="sd">    ```</span>

<span class="sd">    Attributes:</span>
<span class="sd">        params: Dict. Training parameters</span>
<span class="sd">            (eg. verbosity, batch size, number of epochs...).</span>
<span class="sd">        model: Instance of `keras.models.Model`.</span>
<span class="sd">            Reference of the model being trained.</span>

<span class="sd">    The `logs` dictionary that callback methods</span>
<span class="sd">    take as argument will contain keys for quantities relevant to</span>
<span class="sd">    the current batch or epoch (see method-specific docstrings).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># Whether this Callback should only run on the chief worker in a</span>
        <span class="c1"># Multi-Worker setting.</span>
        <span class="c1"># TODO(omalleyt): Make this attr public once solution is stable.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>

    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

<div class="viewcode-block" id="Callback.on_batch_begin"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_batch_begin">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
    <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A backwards compatibility alias for `on_train_batch_begin`.&quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Callback.on_batch_end"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_batch_end">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
    <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A backwards compatibility alias for `on_train_batch_end`.&quot;&quot;&quot;</span></div>

    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the start of an epoch.</span>

<span class="sd">        Subclasses should override for any actions to run. This function should</span>
<span class="sd">        only be called during TRAIN mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch: Integer, index of epoch.</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the end of an epoch.</span>

<span class="sd">        Subclasses should override for any actions to run. This function should</span>
<span class="sd">        only be called during TRAIN mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch: Integer, index of epoch.</span>
<span class="sd">            logs: Dict, metric results for this training epoch, and for the</span>
<span class="sd">              validation epoch if validation is performed. Validation result</span>
<span class="sd">              keys are prefixed with `val_`. For training epoch, the values of</span>
<span class="sd">              the `Model`&#39;s metrics are returned. Example:</span>
<span class="sd">              `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Callback.on_train_batch_begin"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_train_batch_begin">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
    <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the beginning of a training batch in `fit` methods.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">        `tf.keras.Model` is set to `N`, this method will only be called every</span>
<span class="sd">        `N` batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># For backwards compatibility.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Callback.on_train_batch_end"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_train_batch_end">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
    <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the end of a training batch in `fit` methods.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">        `tf.keras.Model` is set to `N`, this method will only be called every</span>
<span class="sd">        `N` batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># For backwards compatibility.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Callback.on_test_batch_begin"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_test_batch_begin">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
    <span class="k">def</span> <span class="nf">on_test_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the beginning of a batch in `evaluate` methods.</span>

<span class="sd">        Also called at the beginning of a validation batch in the `fit`</span>
<span class="sd">        methods, if validation data is provided.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">        `tf.keras.Model` is set to `N`, this method will only be called every</span>
<span class="sd">        `N` batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Callback.on_test_batch_end"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_test_batch_end">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
    <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the end of a batch in `evaluate` methods.</span>

<span class="sd">        Also called at the end of a validation batch in the `fit`</span>
<span class="sd">        methods, if validation data is provided.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">        `tf.keras.Model` is set to `N`, this method will only be called every</span>
<span class="sd">        `N` batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Callback.on_predict_batch_begin"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_predict_batch_begin">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
    <span class="k">def</span> <span class="nf">on_predict_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the beginning of a batch in `predict` methods.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">        `tf.keras.Model` is set to `N`, this method will only be called every</span>
<span class="sd">        `N` batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Callback.on_predict_batch_end"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_predict_batch_end">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
    <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the end of a batch in `predict` methods.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">        `tf.keras.Model` is set to `N`, this method will only be called every</span>
<span class="sd">        `N` batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer, index of batch within the current epoch.</span>
<span class="sd">            logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the beginning of training.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Callback.on_train_end"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_train_end">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the end of training.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently the output of the last call to</span>
<span class="sd">              `on_epoch_end()` is passed to this argument for this method but</span>
<span class="sd">              that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Callback.on_test_begin"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_test_begin">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the beginning of evaluation or validation.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Callback.on_test_end"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_test_end">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the end of evaluation or validation.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently the output of the last call to</span>
<span class="sd">              `on_test_batch_end()` is passed to this argument for this method</span>
<span class="sd">              but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Callback.on_predict_begin"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_predict_begin">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the beginning of prediction.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="Callback.on_predict_end"><a class="viewcode-back" href="../../../_autosummary/gcdyn.nn.Callback.html#gcdyn.nn.Callback.on_predict_end">[docs]</a>    <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
    <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called at the end of prediction.</span>

<span class="sd">        Subclasses should override for any actions to run.</span>

<span class="sd">        Args:</span>
<span class="sd">            logs: Dict. Currently no data is passed to this argument for this</span>
<span class="sd">              method but that may change in the future.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

    <span class="k">def</span> <span class="nf">_implements_train_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Determines if this Callback should be called for each train batch.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span><span class="p">)</span>
            <span class="ow">or</span> <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">)</span>
            <span class="ow">or</span> <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">)</span>
            <span class="ow">or</span> <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_implements_test_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Determines if this Callback should be called for each test batch.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_test_batch_begin</span>
        <span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_test_batch_end</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_implements_predict_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Determines if this Callback should be called for each predict</span>
<span class="sd">        batch.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_predict_batch_begin</span>
        <span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_predict_batch_end</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.BaseLogger&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">BaseLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback that accumulates epoch averages of metrics.</span>

<span class="sd">    This callback is automatically applied to every Keras model.</span>

<span class="sd">    Args:</span>
<span class="sd">        stateful_metrics: Iterable of string names of metrics that</span>
<span class="sd">            should *not* be averaged over an epoch.</span>
<span class="sd">            Metrics in this list will be logged as-is in `on_epoch_end`.</span>
<span class="sd">            All others will be averaged in `on_epoch_end`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stateful_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stateful_metrics</span> <span class="ow">or</span> <span class="p">[])</span>

    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">totals</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="c1"># In case of distribution strategy we can potentially run multiple steps</span>
        <span class="c1"># at the same time, we should account for that in the `seen`</span>
        <span class="c1"># calculation.</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_steps&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_steps</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">batch_size</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">logs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;metrics&quot;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">:</span>
                    <span class="c1"># Make value available to next callbacks.</span>
                    <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">:</span>
                        <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">seen</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.TerminateOnNaN&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TerminateOnNaN</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback that terminates training when a NaN loss is encountered.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
                <span class="n">io_utils</span><span class="o">.</span><span class="n">print_msg</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Batch </span><span class="si">{</span><span class="n">batch</span><span class="si">}</span><span class="s2">: Invalid loss, terminating training&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.ProgbarLogger&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ProgbarLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback that prints metrics to stdout.</span>

<span class="sd">    Args:</span>
<span class="sd">        count_mode: One of `&quot;steps&quot;` or `&quot;samples&quot;`.</span>
<span class="sd">            Whether the progress bar should</span>
<span class="sd">            count samples seen or steps (batches) seen.</span>
<span class="sd">        stateful_metrics: Iterable of string names of metrics that</span>
<span class="sd">            should *not* be averaged over an epoch.</span>
<span class="sd">            Metrics in this list will be logged as-is.</span>
<span class="sd">            All others will be averaged over time (e.g. loss, etc).</span>
<span class="sd">            If not provided, defaults to the `Model`&#39;s metrics.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of invalid `count_mode`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;samples&quot;</span><span class="p">,</span> <span class="n">stateful_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">count_mode</span> <span class="o">==</span> <span class="s2">&quot;samples&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">count_mode</span> <span class="o">==</span> <span class="s2">&quot;steps&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unknown `count_mode`: </span><span class="si">{</span><span class="n">count_mode</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="s1">&#39;Expected values are [&quot;samples&quot;, &quot;steps&quot;]&#39;</span>
            <span class="p">)</span>
        <span class="c1"># Defaults to all Model&#39;s metrics except for loss.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="n">stateful_metrics</span><span class="p">)</span> <span class="k">if</span> <span class="n">stateful_metrics</span> <span class="k">else</span> <span class="nb">set</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_step</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="ow">and</span> <span class="s2">&quot;steps&quot;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;steps&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="ow">and</span> <span class="s2">&quot;samples&quot;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;samples&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="p">(</span>
                <span class="kc">None</span>  <span class="c1"># Will be inferred at the end of the first epoch.</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_train_counter</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_test_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_test_counter</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_predict_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_predict_counter</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># When this logger is called inside `fit`, validation is silent.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reset_progbar</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_init_progbar</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_progbar</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_init_progbar</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_progbar</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_init_progbar</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">io_utils</span><span class="o">.</span><span class="n">print_msg</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_update_progbar</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_update_progbar</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Don&#39;t pass prediction results.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_update_progbar</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_finalize_progbar</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_finalize_progbar</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_step</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_finalize_progbar</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_step</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_reset_progbar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_maybe_init_progbar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Instantiate a `Progbar` if not yet, and update the stateful</span>
<span class="sd">        metrics.&quot;&quot;&quot;</span>
        <span class="c1"># TODO(rchao): Legacy TF1 code path may use list for</span>
        <span class="c1"># `self.stateful_metrics`. Remove &quot;cast to set&quot; when TF1 support is</span>
        <span class="c1"># dropped.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span>
            <span class="c1"># Update the existing stateful metrics as `self.model.metrics` may</span>
            <span class="c1"># contain updated metrics after `MetricsContainer` is built in the</span>
            <span class="c1"># first train step.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>
                <span class="nb">set</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="o">=</span> <span class="n">Progbar</span><span class="p">(</span>
                <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">stateful_metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">,</span>
                <span class="n">unit_name</span><span class="o">=</span><span class="s2">&quot;step&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="k">else</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">_update_stateful_metrics</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_implements_train_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span>

    <span class="k">def</span> <span class="nf">_implements_test_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span>

    <span class="k">def</span> <span class="nf">_implements_predict_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span>

    <span class="k">def</span> <span class="nf">_batch_update_progbar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates the progbar.&quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_init_progbar</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># One-indexed.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># v1 path only.</span>
            <span class="n">logs</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">num_steps</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;num_steps&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">logs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">add_seen</span> <span class="o">=</span> <span class="n">num_steps</span> <span class="o">*</span> <span class="n">batch_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">add_seen</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Only block async when verbose = 1.</span>
            <span class="n">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seen</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">finalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_finalize_progbar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">counter</span><span class="p">):</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span> <span class="ow">or</span> <span class="p">{})</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">counter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">counter</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span><span class="p">:</span>
                    <span class="n">counter</span> <span class="o">*=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">counter</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">seen</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">finalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.History&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">History</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback that records events into a `History` object.</span>

<span class="sd">    This callback is automatically applied to</span>
<span class="sd">    every Keras model. The `History` object</span>
<span class="sd">    gets returned by the `fit` method of models.</span>

<span class="sd">    Example:</span>

<span class="sd">    &gt;&gt;&gt; model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])</span>
<span class="sd">    &gt;&gt;&gt; model.compile(tf.keras.optimizers.SGD(), loss=&#39;mse&#39;)</span>
<span class="sd">    &gt;&gt;&gt; history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),</span>
<span class="sd">    ...                     epochs=10, verbose=1)</span>
<span class="sd">    &gt;&gt;&gt; print(history.params)</span>
<span class="sd">    {&#39;verbose&#39;: 1, &#39;epochs&#39;: 10, &#39;steps&#39;: 1}</span>
<span class="sd">    &gt;&gt;&gt; # check the keys of history object</span>
<span class="sd">    &gt;&gt;&gt; print(history.history.keys())</span>
<span class="sd">    dict_keys([&#39;loss&#39;])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="c1"># Set the history attribute on the model after the epoch ends. This will</span>
        <span class="c1"># make sure that the state which is set is the latest one.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="bp">self</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.ModelCheckpoint&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback to save the Keras model or model weights at some frequency.</span>

<span class="sd">    `ModelCheckpoint` callback is used in conjunction with training using</span>
<span class="sd">    `model.fit()` to save a model or weights (in a checkpoint file) at some</span>
<span class="sd">    interval, so the model or weights can be loaded later to continue the</span>
<span class="sd">    training from the state saved.</span>

<span class="sd">    A few options this callback provides include:</span>

<span class="sd">    - Whether to only keep the model that has achieved the &quot;best performance&quot; so</span>
<span class="sd">      far, or whether to save the model at the end of every epoch regardless of</span>
<span class="sd">      performance.</span>
<span class="sd">    - Definition of &#39;best&#39;; which quantity to monitor and whether it should be</span>
<span class="sd">      maximized or minimized.</span>
<span class="sd">    - The frequency it should save at. Currently, the callback supports saving</span>
<span class="sd">      at the end of every epoch, or after a fixed number of training batches.</span>
<span class="sd">    - Whether only weights are saved, or the whole model is saved.</span>

<span class="sd">    Note: If you get `WARNING:tensorflow:Can save best model only with &lt;name&gt;</span>
<span class="sd">    available, skipping` see the description of the `monitor` argument for</span>
<span class="sd">    details on how to get this right.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    model.compile(loss=..., optimizer=...,</span>
<span class="sd">                  metrics=[&#39;accuracy&#39;])</span>

<span class="sd">    EPOCHS = 10</span>
<span class="sd">    checkpoint_filepath = &#39;/tmp/checkpoint&#39;</span>
<span class="sd">    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(</span>
<span class="sd">        filepath=checkpoint_filepath,</span>
<span class="sd">        save_weights_only=True,</span>
<span class="sd">        monitor=&#39;val_accuracy&#39;,</span>
<span class="sd">        mode=&#39;max&#39;,</span>
<span class="sd">        save_best_only=True)</span>

<span class="sd">    # Model weights are saved at the end of every epoch, if it&#39;s the best seen</span>
<span class="sd">    # so far.</span>
<span class="sd">    model.fit(epochs=EPOCHS, callbacks=[model_checkpoint_callback])</span>

<span class="sd">    # The model weights (that are considered the best) are loaded into the</span>
<span class="sd">    # model.</span>
<span class="sd">    model.load_weights(checkpoint_filepath)</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">        filepath: string or `PathLike`, path to save the model file. e.g.</span>
<span class="sd">          filepath = os.path.join(working_dir, &#39;ckpt&#39;, file_name). `filepath`</span>
<span class="sd">          can contain named formatting options, which will be filled the value</span>
<span class="sd">          of `epoch` and keys in `logs` (passed in `on_epoch_end`). For example:</span>
<span class="sd">          if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`, then the</span>
<span class="sd">          model checkpoints will be saved with the epoch number and the</span>
<span class="sd">          validation loss in the filename. The directory of the filepath should</span>
<span class="sd">          not be reused by any other callbacks to avoid conflicts.</span>
<span class="sd">        monitor: The metric name to monitor. Typically the metrics are set by</span>
<span class="sd">          the `Model.compile` method. Note:</span>

<span class="sd">          * Prefix the name with `&quot;val_`&quot; to monitor validation metrics.</span>
<span class="sd">          * Use `&quot;loss&quot;` or &quot;`val_loss`&quot; to monitor the model&#39;s total loss.</span>
<span class="sd">          * If you specify metrics as strings, like `&quot;accuracy&quot;`, pass the same</span>
<span class="sd">            string (with or without the `&quot;val_&quot;` prefix).</span>
<span class="sd">          * If you pass `metrics.Metric` objects, `monitor` should be set to</span>
<span class="sd">            `metric.name`</span>
<span class="sd">          * If you&#39;re not sure about the metric names you can check the contents</span>
<span class="sd">            of the `history.history` dictionary returned by</span>
<span class="sd">            `history = model.fit()`</span>
<span class="sd">          * Multi-output models set additional prefixes on the metric names.</span>

<span class="sd">        verbose: Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1</span>
<span class="sd">          displays messages when the callback takes an action.</span>
<span class="sd">        save_best_only: if `save_best_only=True`, it only saves when the model</span>
<span class="sd">          is considered the &quot;best&quot; and the latest best model according to the</span>
<span class="sd">          quantity monitored will not be overwritten. If `filepath` doesn&#39;t</span>
<span class="sd">          contain formatting options like `{epoch}` then `filepath` will be</span>
<span class="sd">          overwritten by each new better model.</span>
<span class="sd">        mode: one of {&#39;auto&#39;, &#39;min&#39;, &#39;max&#39;}. If `save_best_only=True`, the</span>
<span class="sd">          decision to overwrite the current save file is made based on either</span>
<span class="sd">          the maximization or the minimization of the monitored quantity.</span>
<span class="sd">          For `val_acc`, this should be `max`, for `val_loss` this should be</span>
<span class="sd">          `min`, etc. In `auto` mode, the mode is set to `max` if the quantities</span>
<span class="sd">          monitored are &#39;acc&#39; or start with &#39;fmeasure&#39; and are set to `min` for</span>
<span class="sd">          the rest of the quantities.</span>
<span class="sd">        save_weights_only: if True, then only the model&#39;s weights will be saved</span>
<span class="sd">          (`model.save_weights(filepath)`), else the full model is saved</span>
<span class="sd">          (`model.save(filepath)`).</span>
<span class="sd">        save_freq: `&#39;epoch&#39;` or integer. When using `&#39;epoch&#39;`, the callback</span>
<span class="sd">          saves the model after each epoch. When using integer, the callback</span>
<span class="sd">          saves the model at end of this many batches. If the `Model` is</span>
<span class="sd">          compiled with `steps_per_execution=N`, then the saving criteria will</span>
<span class="sd">          be checked every Nth batch. Note that if the saving isn&#39;t aligned to</span>
<span class="sd">          epochs, the monitored metric may potentially be less reliable (it</span>
<span class="sd">          could reflect as little as 1 batch, since the metrics get reset every</span>
<span class="sd">          epoch). Defaults to `&#39;epoch&#39;`.</span>
<span class="sd">        options: Optional `tf.train.CheckpointOptions` object if</span>
<span class="sd">          `save_weights_only` is true or optional `tf.saved_model.SaveOptions`</span>
<span class="sd">          object if `save_weights_only` is false.</span>
<span class="sd">        initial_value_threshold: Floating point initial &quot;best&quot; value of the</span>
<span class="sd">          metric to be monitored. Only applies if `save_best_value=True`. Only</span>
<span class="sd">          overwrites the model weights already saved if the performance of</span>
<span class="sd">          current model is better than this value.</span>
<span class="sd">        **kwargs: Additional arguments for backwards compatibility. Possible key</span>
<span class="sd">          is `period`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">filepath</span><span class="p">,</span>
        <span class="n">monitor</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">save_best_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">save_weights_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">save_freq</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
        <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">initial_value_threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">=</span> <span class="n">io_utils</span><span class="o">.</span><span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_best_only</span> <span class="o">=</span> <span class="n">save_best_only</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span> <span class="o">=</span> <span class="n">save_weights_only</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">=</span> <span class="n">save_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batches_seen_since_last_saving</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_seen</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">initial_value_threshold</span>

        <span class="k">if</span> <span class="n">save_weights_only</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">options</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointOptions</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_options</span> <span class="o">=</span> <span class="n">options</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointOptions</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;If save_weights_only is True, then `options` must be &quot;</span>
                    <span class="s2">&quot;either None or a tf.train.CheckpointOptions. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="n">options</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">filepath</span> <span class="ow">and</span> <span class="n">filepath</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.keras&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">options</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The native Keras format does not support &quot;</span>
                    <span class="s2">&quot;the `options` argument. Please remove &quot;</span>
                    <span class="s2">&quot;the `options` argument, or use the SavedModel &quot;</span>
                    <span class="s2">&quot;format by removing the `.keras` extension from &quot;</span>
                    <span class="s2">&quot;the model filepath.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">options</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">SaveOptions</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_options</span> <span class="o">=</span> <span class="n">options</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">SaveOptions</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;If save_weights_only is False, then `options` must be &quot;</span>
                    <span class="s2">&quot;either None or a tf.saved_model.SaveOptions. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="n">options</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

        <span class="c1"># Deprecated field `load_weights_on_restart` is for loading the</span>
        <span class="c1"># checkpoint file from `filepath` at the start of `model.fit()`</span>
        <span class="c1"># TODO(rchao): Remove the arg during next breaking release.</span>
        <span class="k">if</span> <span class="s2">&quot;load_weights_on_restart&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;load_weights_on_restart&quot;</span><span class="p">]</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;`load_weights_on_restart` argument is deprecated. &quot;</span>
                <span class="s2">&quot;Please use `model.load_weights()` for loading weights &quot;</span>
                <span class="s2">&quot;before the start of `model.fit()`.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Deprecated field `period` is for the number of epochs between which</span>
        <span class="c1"># the model is saved.</span>
        <span class="k">if</span> <span class="s2">&quot;period&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;period&quot;</span><span class="p">]</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;`period` argument is deprecated. Please use `save_freq` &quot;</span>
                <span class="s2">&quot;to specify the frequency in number of batches seen.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">]:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;ModelCheckpoint mode </span><span class="si">%s</span><span class="s2"> is unknown, fallback to auto mode.&quot;</span><span class="p">,</span>
                <span class="n">mode</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;acc&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;fmeasure&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">!=</span> <span class="s2">&quot;epoch&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unrecognized save_freq: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="s1">&#39;Expected save_freq are &quot;epoch&quot; or integer&#39;</span>
            <span class="p">)</span>

        <span class="c1"># Only the chief worker writes model checkpoints, but all workers</span>
        <span class="c1"># restore checkpoint at on_train_begin().</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span><span class="p">:</span>
            <span class="n">filepath_to_load</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_get_most_recently_modified_file_matching_pattern</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">filepath_to_load</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_exists</span><span class="p">(</span>
                <span class="n">filepath_to_load</span>
            <span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># `filepath` may contain placeholders such as `{epoch:02d}`,</span>
                    <span class="c1"># and thus it attempts to load the most recently modified</span>
                    <span class="c1"># file with file name matching the pattern.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">filepath_to_load</span><span class="p">)</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">IOError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Error loading file from </span><span class="si">{</span><span class="n">filepath_to_load</span><span class="si">}</span><span class="s2">. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Reason: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_implements_train_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Only call batch hooks when saving on batch</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">!=</span> <span class="s2">&quot;epoch&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_save_on_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="s2">&quot;epoch&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_should_save_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Handles batch-level saving logic, supports steps_per_execution.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="s2">&quot;epoch&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">batch</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_seen</span><span class="p">:</span>  <span class="c1"># New epoch.</span>
            <span class="n">add_batches</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># batches are zero-indexed.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">add_batches</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_seen</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batches_seen_since_last_saving</span> <span class="o">+=</span> <span class="n">add_batches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_seen</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batches_seen_since_last_saving</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batches_seen_since_last_saving</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Saves the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch: the epoch this iteration is in.</span>
<span class="sd">            batch: the batch this iteration is in. `None` if the `save_freq`</span>
<span class="sd">              is set to `epoch`.</span>
<span class="sd">            logs: the `logs` dict passed in to `on_batch_end` or `on_epoch_end`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span>
        <span class="p">):</span>
            <span class="c1"># Block only when saving interval is reached.</span>
            <span class="n">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_path</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

            <span class="n">dirname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">dirname</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="n">dirname</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;gs://&quot;</span><span class="p">)</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dirname</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dirname</span><span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_best_only</span><span class="p">:</span>
                    <span class="n">current</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="s2">&quot;Can save best model only with </span><span class="si">%s</span><span class="s2"> available, &quot;</span>
                            <span class="s2">&quot;skipping.&quot;</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                                <span class="n">io_utils</span><span class="o">.</span><span class="n">print_msg</span><span class="p">(</span>
                                    <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="si">}</span><span class="s2"> &quot;</span>
                                    <span class="s2">&quot;improved &quot;</span>
                                    <span class="sa">f</span><span class="s2">&quot;from </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">current</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">, &quot;</span>
                                    <span class="sa">f</span><span class="s2">&quot;saving model to </span><span class="si">{</span><span class="n">filepath</span><span class="si">}</span><span class="s2">&quot;</span>
                                <span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>

                            <span class="c1"># Handles saving and corresponding options</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_save_handler</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                                <span class="n">io_utils</span><span class="o">.</span><span class="n">print_msg</span><span class="p">(</span>
                                    <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: &quot;</span>
                                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="si">}</span><span class="s2"> did not improve &quot;</span>
                                    <span class="sa">f</span><span class="s2">&quot;from </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span>
                                <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">io_utils</span><span class="o">.</span><span class="n">print_msg</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: saving model to </span><span class="si">{</span><span class="n">filepath</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>

                    <span class="c1"># Handles saving and corresponding options</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_save_handler</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_remove_file</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">IsADirectoryError</span><span class="p">:</span>  <span class="c1"># h5py 3.x</span>
                <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span>
                    <span class="s2">&quot;Please specify a non-directory filepath for &quot;</span>
                    <span class="s2">&quot;ModelCheckpoint. Filepath used is an existing &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;directory: </span><span class="si">{</span><span class="n">filepath</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">IOError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># h5py 2.x</span>
                <span class="c1"># `e.errno` appears to be `None` so checking the content of</span>
                <span class="c1"># `e.args[0]`.</span>
                <span class="k">if</span> <span class="s2">&quot;is a directory&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span>
                        <span class="s2">&quot;Please specify a non-directory filepath for &quot;</span>
                        <span class="s2">&quot;ModelCheckpoint. Filepath used is an existing &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;directory: f</span><span class="si">{</span><span class="n">filepath</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="c1"># Re-throw the error for any other causes.</span>
                <span class="k">raise</span> <span class="n">e</span>

    <span class="k">def</span> <span class="nf">_save_handler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">filepath</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.weights.h5&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span>
                    <span class="n">filepath</span><span class="p">,</span>
                    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span>
                    <span class="n">filepath</span><span class="p">,</span>
                    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">filepath</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.keras&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                    <span class="n">filepath</span><span class="p">,</span>
                    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_file_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the file path for checkpoint.&quot;&quot;&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># `filepath` may contain placeholders such as</span>
            <span class="c1"># `{epoch:02d}`,`{batch:02d}` and `{mape:.2f}`. A mismatch between</span>
            <span class="c1"># logged metrics and the path&#39;s placeholders can cause formatting to</span>
            <span class="c1"># fail.</span>
            <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="s2">&quot;batch&quot;</span> <span class="ow">in</span> <span class="n">logs</span><span class="p">:</span>
                <span class="n">file_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">logs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">file_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">logs</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;Failed to format this callback filepath: &quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="si">}</span><span class="s1">&quot;. &#39;</span>
                <span class="sa">f</span><span class="s2">&quot;Reason: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_write_filepath</span> <span class="o">=</span> <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">write_filepath</span><span class="p">(</span>
            <span class="n">file_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_write_filepath</span>

    <span class="k">def</span> <span class="nf">_maybe_remove_file</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Remove the checkpoint directory in multi-worker training where this</span>
        <span class="c1"># worker should not checkpoint. It is a dummy directory previously saved</span>
        <span class="c1"># for sync distributed training.</span>
        <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">remove_temp_dir_with_filepath</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_write_filepath</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_checkpoint_exists</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns whether the checkpoint `filepath` refers to exists.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">filepath</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.h5&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
        <span class="n">tf_saved_model_exists</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
        <span class="n">tf_weights_only_checkpoint_exists</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span>
            <span class="n">filepath</span> <span class="o">+</span> <span class="s2">&quot;.index&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tf_saved_model_exists</span> <span class="ow">or</span> <span class="n">tf_weights_only_checkpoint_exists</span>

    <span class="k">def</span> <span class="nf">_get_most_recently_modified_file_matching_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pattern</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the most recently modified filepath matching pattern.</span>

<span class="sd">        Pattern may contain python formatting placeholder. If</span>
<span class="sd">        `tf.train.latest_checkpoint()` does not return None, use that;</span>
<span class="sd">        otherwise, check for most recently modified one that matches the</span>
<span class="sd">        pattern.</span>

<span class="sd">        In the rare case where there are more than one pattern-matching file</span>
<span class="sd">        having the same modified time that is most recent among all, return the</span>
<span class="sd">        filepath that is largest (by `&gt;` operator, lexicographically using the</span>
<span class="sd">        numeric equivalents). This provides a tie-breaker when multiple files</span>
<span class="sd">        are most recent. Note that a larger `filepath` can sometimes indicate a</span>
<span class="sd">        later time of modification (for instance, when epoch/batch is used as</span>
<span class="sd">        formatting option), but not necessarily (when accuracy or loss is used).</span>
<span class="sd">        The tie-breaker is put in the logic as best effort to return the most</span>
<span class="sd">        recent, and to avoid undeterministic result.</span>

<span class="sd">        Modified time of a file is obtained with `os.path.getmtime()`.</span>

<span class="sd">        This utility function is best demonstrated via an example:</span>

<span class="sd">        ```python</span>
<span class="sd">        file_pattern = &#39;f.batch{batch:02d}epoch{epoch:02d}.h5&#39;</span>
<span class="sd">        test_dir = self.get_temp_dir()</span>
<span class="sd">        path_pattern = os.path.join(test_dir, file_pattern)</span>
<span class="sd">        file_paths = [</span>
<span class="sd">            os.path.join(test_dir, file_name) for file_name in</span>
<span class="sd">            [&#39;f.batch03epoch02.h5&#39;,</span>
<span class="sd">             &#39;f.batch02epoch02.h5&#39;, &#39;f.batch01epoch01.h5&#39;]</span>
<span class="sd">        ]</span>
<span class="sd">        for file_path in file_paths:</span>
<span class="sd">          # Write something to each of the files</span>
<span class="sd">        self.assertEqual(</span>
<span class="sd">            _get_most_recently_modified_file_matching_pattern(path_pattern),</span>
<span class="sd">            file_paths[-1])</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">            pattern: The file pattern that may optionally contain python</span>
<span class="sd">                placeholder such as `{epoch:02d}`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The most recently modified file&#39;s full filepath matching `pattern`.</span>
<span class="sd">            If `pattern` does not contain any placeholder, this returns the</span>
<span class="sd">            filepath that exactly matches `pattern`. Returns `None` if no match</span>
<span class="sd">            is found.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dir_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
        <span class="n">base_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
        <span class="n">base_name_regex</span> <span class="o">=</span> <span class="s2">&quot;^&quot;</span> <span class="o">+</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;{.*}&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;.*&quot;</span><span class="p">,</span> <span class="n">base_name</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;$&quot;</span>

        <span class="c1"># If tf.train.latest_checkpoint tells us there exists a latest</span>
        <span class="c1"># checkpoint, use that as it is more robust than `os.path.getmtime()`.</span>
        <span class="n">latest_tf_checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">dir_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">latest_tf_checkpoint</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span>
            <span class="n">base_name_regex</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">latest_tf_checkpoint</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">latest_tf_checkpoint</span>

        <span class="n">latest_mod_time</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">file_path_with_latest_mod_time</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">n_file_with_latest_mod_time</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">file_path_with_largest_file_name</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
                <span class="c1"># Only consider if `file_name` matches the pattern.</span>
                <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">base_name_regex</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
                    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
                    <span class="n">mod_time</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getmtime</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">file_path_with_largest_file_name</span> <span class="ow">is</span> <span class="kc">None</span>
                        <span class="ow">or</span> <span class="n">file_path</span> <span class="o">&gt;</span> <span class="n">file_path_with_largest_file_name</span>
                    <span class="p">):</span>
                        <span class="n">file_path_with_largest_file_name</span> <span class="o">=</span> <span class="n">file_path</span>
                    <span class="k">if</span> <span class="n">mod_time</span> <span class="o">&gt;</span> <span class="n">latest_mod_time</span><span class="p">:</span>
                        <span class="n">latest_mod_time</span> <span class="o">=</span> <span class="n">mod_time</span>
                        <span class="n">file_path_with_latest_mod_time</span> <span class="o">=</span> <span class="n">file_path</span>
                        <span class="c1"># In the case a file with later modified time is found,</span>
                        <span class="c1"># reset the counter for the number of files with latest</span>
                        <span class="c1"># modified time.</span>
                        <span class="n">n_file_with_latest_mod_time</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">elif</span> <span class="n">mod_time</span> <span class="o">==</span> <span class="n">latest_mod_time</span><span class="p">:</span>
                        <span class="c1"># In the case a file has modified time tied with the</span>
                        <span class="c1"># most recent, increment the counter for the number of</span>
                        <span class="c1"># files with latest modified time by 1.</span>
                        <span class="n">n_file_with_latest_mod_time</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">n_file_with_latest_mod_time</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Return the sole file that has most recent modified time.</span>
            <span class="k">return</span> <span class="n">file_path_with_latest_mod_time</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If there are more than one file having latest modified time,</span>
            <span class="c1"># return the file path with the largest file name.</span>
            <span class="k">return</span> <span class="n">file_path_with_largest_file_name</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.BackupAndRestore&quot;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[])</span>
<span class="k">class</span> <span class="nc">BackupAndRestore</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback to back up and restore the training state.</span>

<span class="sd">    `BackupAndRestore` callback is intended to recover training from an</span>
<span class="sd">    interruption that has happened in the middle of a `Model.fit` execution, by</span>
<span class="sd">    backing up the training states in a temporary checkpoint file (with the help</span>
<span class="sd">    of a `tf.train.CheckpointManager`), at the end of each epoch. Each backup</span>
<span class="sd">    overwrites the previously written checkpoint file, so at any given time</span>
<span class="sd">    there is at most one such checkpoint file for backup/restoring purpose.</span>

<span class="sd">    If training restarts before completion, the training state (which includes</span>
<span class="sd">    the `Model` weights and epoch number) is restored to the most recently saved</span>
<span class="sd">    state at the beginning of a new `Model.fit` run. At the completion of a</span>
<span class="sd">    `Model.fit` run, the temporary checkpoint file is deleted.</span>

<span class="sd">    Note that the user is responsible to bring jobs back after the interruption.</span>
<span class="sd">    This callback is important for the backup and restore mechanism for fault</span>
<span class="sd">    tolerance purpose, and the model to be restored from a previous checkpoint</span>
<span class="sd">    is expected to be the same as the one used to back up. If user changes</span>
<span class="sd">    arguments passed to compile or fit, the checkpoint saved for fault tolerance</span>
<span class="sd">    can become invalid.</span>

<span class="sd">    Note:</span>

<span class="sd">    1. This callback is not compatible with eager execution disabled.</span>
<span class="sd">    2. A checkpoint is saved at the end of each epoch. After restoring,</span>
<span class="sd">    `Model.fit` redoes any partial work during the unfinished epoch in which the</span>
<span class="sd">    training got restarted (so the work done before the interruption doesn&#39;t</span>
<span class="sd">    affect the final model state).</span>
<span class="sd">    3. This works for both single worker and multi-worker modes. When</span>
<span class="sd">    `Model.fit` is used with `tf.distribute`, it supports</span>
<span class="sd">    `tf.distribute.MirroredStrategy`,</span>
<span class="sd">    `tf.distribute.MultiWorkerMirroredStrategy`, `tf.distribute.TPUStrategy`,</span>
<span class="sd">    and `tf.distribute.experimental.ParameterServerStrategy`.</span>

<span class="sd">    Example:</span>

<span class="sd">    &gt;&gt;&gt; class InterruptingCallback(tf.keras.callbacks.Callback):</span>
<span class="sd">    ...   def on_epoch_begin(self, epoch, logs=None):</span>
<span class="sd">    ...     if epoch == 4:</span>
<span class="sd">    ...       raise RuntimeError(&#39;Interrupting!&#39;)</span>
<span class="sd">    &gt;&gt;&gt; callback = tf.keras.callbacks.BackupAndRestore(backup_dir=&quot;/tmp/backup&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])</span>
<span class="sd">    &gt;&gt;&gt; model.compile(tf.keras.optimizers.SGD(), loss=&#39;mse&#39;)</span>
<span class="sd">    &gt;&gt;&gt; try:</span>
<span class="sd">    ...   model.fit(np.arange(100).reshape(5, 20), np.zeros(5), epochs=10,</span>
<span class="sd">    ...             batch_size=1, callbacks=[callback, InterruptingCallback()],</span>
<span class="sd">    ...             verbose=0)</span>
<span class="sd">    ... except:</span>
<span class="sd">    ...   pass</span>
<span class="sd">    &gt;&gt;&gt; history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),</span>
<span class="sd">    ...                     epochs=10, batch_size=1, callbacks=[callback],</span>
<span class="sd">    ...                     verbose=0)</span>
<span class="sd">    &gt;&gt;&gt; # Only 6 more epochs are run, since first training got interrupted at</span>
<span class="sd">    &gt;&gt;&gt; # zero-indexed epoch 4, second training will continue from 4 to 9.</span>
<span class="sd">    &gt;&gt;&gt; len(history.history[&#39;loss&#39;])</span>
<span class="sd">    6</span>

<span class="sd">    Besides the option to save at the end of every epoch or every N steps, if</span>
<span class="sd">    you are doing distributed training with</span>
<span class="sd">    `tf.distribute.MultiWorkerMirroredStrategy` on Google Cloud Platform or</span>
<span class="sd">    Google Borg, you can also use the `save_before_preemption` argument</span>
<span class="sd">    to enable saving a checkpoint right before a worker gets preempted</span>
<span class="sd">    by other jobs and training gets interrupted. See</span>
<span class="sd">    `tf.distribute.experimental.PreemptionCheckpointHandler` for more details.</span>

<span class="sd">    Args:</span>
<span class="sd">        backup_dir: String, path to store the checkpoint.</span>
<span class="sd">          e.g. `backup_dir = os.path.join(working_dir, &#39;backup&#39;)`.</span>
<span class="sd">          This is the directory in which the system stores temporary files to</span>
<span class="sd">          recover the model from jobs terminated unexpectedly. The directory</span>
<span class="sd">          cannot be reused elsewhere to store other files, e.g. by the</span>
<span class="sd">          `BackupAndRestore` callback of another training run,</span>
<span class="sd">          or by another callback</span>
<span class="sd">          (e.g. `ModelCheckpoint`) of the same training.</span>
<span class="sd">        save_freq: `&#39;epoch&#39;`, integer, or `False`. When set to `&#39;epoch&#39;`</span>
<span class="sd">          the callback saves the checkpoint at the end of each epoch.</span>
<span class="sd">          When set to an integer, the callback saves the checkpoint every</span>
<span class="sd">          `save_freq` batches. Set `save_freq` to `False` if only using</span>
<span class="sd">          preemption checkpointing (with `save_before_preemption=True`).</span>
<span class="sd">        delete_checkpoint: Boolean, default to True. This `BackupAndRestore`</span>
<span class="sd">          callback works by saving a checkpoint to back up the training state.</span>
<span class="sd">          If `delete_checkpoint=True`, the checkpoint will be deleted after</span>
<span class="sd">          training is finished. Use `False` if you&#39;d like to keep the checkpoint</span>
<span class="sd">          for future usage.</span>
<span class="sd">        save_before_preemption: A boolean value instructing whether to turn on</span>
<span class="sd">          the automatic checkpoint saving for preemption/maintenance events.</span>
<span class="sd">          This only supports</span>
<span class="sd">          `tf.distribute.MultiWorkerMirroredStrategy` on Google Cloud Platform</span>
<span class="sd">          or Google Borg for now.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">backup_dir</span><span class="p">,</span>
        <span class="n">save_freq</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
        <span class="n">delete_checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">save_before_preemption</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backup_dir</span> <span class="o">=</span> <span class="n">backup_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_supported_strategies</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">TPUStrategy</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">TPUStrategy</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">ParameterServerStrategy</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">=</span> <span class="n">save_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delete_checkpoint</span> <span class="o">=</span> <span class="n">delete_checkpoint</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_before_preemption</span> <span class="o">=</span> <span class="n">save_before_preemption</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batches_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">inside_function</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;This Callback&#39;s method contains Python state and &quot;</span>
                    <span class="s2">&quot;should be called outside of `tf.function`s.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># Legacy graph mode:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;BackupAndRestore only supports eager mode. In graph &quot;</span>
                    <span class="s2">&quot;mode, consider using ModelCheckpoint to manually save &quot;</span>
                    <span class="s2">&quot;and restore weights with `model.load_weights()` and by &quot;</span>
                    <span class="s2">&quot;providing `initial_epoch` in `model.fit()` for fault &quot;</span>
                    <span class="s2">&quot;tolerance.&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">save_freq</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">save_before_preemption</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Either `save_freq` or `save_before_preemption` &quot;</span> <span class="s2">&quot;must be set.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Only the chief worker writes model checkpoints, but all workers</span>
        <span class="c1"># restore checkpoint at on_train_begin().</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># TrainingState is used to manage the training state needed for</span>
        <span class="c1"># failure-recovery of a worker in training.</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supported_strategies</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not supported yet. &quot;</span>
                <span class="s2">&quot;Currently BackupAndRestore callback &quot;</span>
                <span class="s2">&quot;only supports empty strategy, &quot;</span>
                <span class="s2">&quot;MirroredStrategy, MultiWorkerMirroredStrategy and TPUStrategy.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_training_state</span> <span class="o">=</span> <span class="n">worker_training_state</span><span class="o">.</span><span class="n">WorkerTrainingState</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">backup_dir</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_before_preemption</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_training_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">restore</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Skip batch update for PSS Strategy</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ParameterServerStrategy</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">_ckpt_saved_batch</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Skip batch update for PSS Strategy</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ParameterServerStrategy</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">backup_if_preempted</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">!=</span> <span class="s2">&quot;epoch&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batches_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batches_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_batches_count</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_backup</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_implements_train_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">!=</span> <span class="s2">&quot;epoch&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delete_checkpoint</span><span class="p">:</span>
            <span class="c1"># On exit of training, delete the training state backup file saved</span>
            <span class="c1"># for the purpose of worker recovery unless the user opts out.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">delete_backup</span><span class="p">()</span>
        <span class="c1"># Clean up the training state.</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_training_state</span>

    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">_ckpt_saved_epoch</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Back up the model and current epoch for possible future recovery.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="s2">&quot;epoch&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_backup</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_backup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">back_up</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.experimental.BackupAndRestore&quot;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[])</span>
<span class="nd">@deprecation</span><span class="o">.</span><span class="n">deprecated_endpoints</span><span class="p">(</span>
    <span class="s2">&quot;keras.callbacks.experimental.BackupAndRestore&quot;</span>
<span class="p">)</span>
<span class="k">class</span> <span class="nc">BackupAndRestoreExperimental</span><span class="p">(</span><span class="n">BackupAndRestore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Deprecated. Please use `tf.keras.callbacks.BackupAndRestore` instead.</span>

<span class="sd">    Caution: `tf.keras.callbacks.experimental.BackupAndRestore` endpoint is</span>
<span class="sd">      deprecated and will be removed in a future release. Please use</span>
<span class="sd">      `tf.keras.callbacks.BackupAndRestore`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;`tf.keras.callbacks.experimental.BackupAndRestore` endpoint is &quot;</span>
            <span class="s2">&quot;deprecated and will be removed in a future release. Please use &quot;</span>
            <span class="s2">&quot;`tf.keras.callbacks.BackupAndRestore`.&quot;</span>
        <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.EarlyStopping&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">EarlyStopping</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stop training when a monitored metric has stopped improving.</span>

<span class="sd">    Assuming the goal of a training is to minimize the loss. With this, the</span>
<span class="sd">    metric to be monitored would be `&#39;loss&#39;`, and mode would be `&#39;min&#39;`. A</span>
<span class="sd">    `model.fit()` training loop will check at end of every epoch whether</span>
<span class="sd">    the loss is no longer decreasing, considering the `min_delta` and</span>
<span class="sd">    `patience` if applicable. Once it&#39;s found no longer decreasing,</span>
<span class="sd">    `model.stop_training` is marked True and the training terminates.</span>

<span class="sd">    The quantity to be monitored needs to be available in `logs` dict.</span>
<span class="sd">    To make it so, pass the loss or metrics at `model.compile()`.</span>

<span class="sd">    Args:</span>
<span class="sd">      monitor: Quantity to be monitored.</span>
<span class="sd">      min_delta: Minimum change in the monitored quantity</span>
<span class="sd">          to qualify as an improvement, i.e. an absolute</span>
<span class="sd">          change of less than min_delta, will count as no</span>
<span class="sd">          improvement.</span>
<span class="sd">      patience: Number of epochs with no improvement</span>
<span class="sd">          after which training will be stopped.</span>
<span class="sd">      verbose: Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1</span>
<span class="sd">          displays messages when the callback takes an action.</span>
<span class="sd">      mode: One of `{&quot;auto&quot;, &quot;min&quot;, &quot;max&quot;}`. In `min` mode,</span>
<span class="sd">          training will stop when the quantity</span>
<span class="sd">          monitored has stopped decreasing; in `&quot;max&quot;`</span>
<span class="sd">          mode it will stop when the quantity</span>
<span class="sd">          monitored has stopped increasing; in `&quot;auto&quot;`</span>
<span class="sd">          mode, the direction is automatically inferred</span>
<span class="sd">          from the name of the monitored quantity.</span>
<span class="sd">      baseline: Baseline value for the monitored quantity.</span>
<span class="sd">          Training will stop if the model doesn&#39;t show improvement over the</span>
<span class="sd">          baseline.</span>
<span class="sd">      restore_best_weights: Whether to restore model weights from</span>
<span class="sd">          the epoch with the best value of the monitored quantity.</span>
<span class="sd">          If False, the model weights obtained at the last step of</span>
<span class="sd">          training are used. An epoch will be restored regardless</span>
<span class="sd">          of the performance relative to the `baseline`. If no epoch</span>
<span class="sd">          improves on `baseline`, training will run for `patience`</span>
<span class="sd">          epochs and restore weights from the best epoch in that set.</span>
<span class="sd">      start_from_epoch: Number of epochs to wait before starting</span>
<span class="sd">          to monitor improvement. This allows for a warm-up period in which</span>
<span class="sd">          no improvement is expected and thus training will not be stopped.</span>


<span class="sd">    Example:</span>

<span class="sd">    &gt;&gt;&gt; callback = tf.keras.callbacks.EarlyStopping(monitor=&#39;loss&#39;, patience=3)</span>
<span class="sd">    &gt;&gt;&gt; # This callback will stop the training when there is no improvement in</span>
<span class="sd">    &gt;&gt;&gt; # the loss for three consecutive epochs.</span>
<span class="sd">    &gt;&gt;&gt; model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])</span>
<span class="sd">    &gt;&gt;&gt; model.compile(tf.keras.optimizers.SGD(), loss=&#39;mse&#39;)</span>
<span class="sd">    &gt;&gt;&gt; history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),</span>
<span class="sd">    ...                     epochs=10, batch_size=1, callbacks=[callback],</span>
<span class="sd">    ...                     verbose=0)</span>
<span class="sd">    &gt;&gt;&gt; len(history.history[&#39;loss&#39;])  # Only 4 epochs are run.</span>
<span class="sd">    4</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
        <span class="n">min_delta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">start_from_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="o">=</span> <span class="n">baseline</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">min_delta</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span> <span class="o">=</span> <span class="n">restore_best_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_from_epoch</span> <span class="o">=</span> <span class="n">start_from_epoch</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">]:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;EarlyStopping mode </span><span class="si">%s</span><span class="s2"> is unknown, fallback to auto mode.&quot;</span><span class="p">,</span>
                <span class="n">mode</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;acc&quot;</span><span class="p">)</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;auc&quot;</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">*=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Allow instances to be re-used</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span> <span class="k">else</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">current</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_monitor_value</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_from_epoch</span><span class="p">:</span>
            <span class="c1"># If no monitor value exists or still in initial warm-up stage.</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Restore the weights after first epoch if no progress is ever made.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_improvement</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
            <span class="c1"># Only restart wait if we beat both the baseline and our previous</span>
            <span class="c1"># best.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_improvement</span><span class="p">(</span>
                <span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">return</span>

        <span class="c1"># Only check after the first epoch.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">io_utils</span><span class="o">.</span><span class="n">print_msg</span><span class="p">(</span>
                        <span class="s2">&quot;Restoring model weights from &quot;</span>
                        <span class="s2">&quot;the end of the best epoch: &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">io_utils</span><span class="o">.</span><span class="n">print_msg</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: early stopping&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_monitor_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">monitor_value</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">monitor_value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Early stopping conditioned on metric `</span><span class="si">%s</span><span class="s2">` &quot;</span>
                <span class="s2">&quot;which is not available. Available metrics are: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span>
                <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())),</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">monitor_value</span>

    <span class="k">def</span> <span class="nf">_is_improvement</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">monitor_value</span><span class="p">,</span> <span class="n">reference_value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">monitor_value</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">,</span> <span class="n">reference_value</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.RemoteMonitor&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RemoteMonitor</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback used to stream events to a server.</span>

<span class="sd">    Requires the `requests` library.</span>
<span class="sd">    Events are sent to `root + &#39;/publish/epoch/end/&#39;` by default. Calls are</span>
<span class="sd">    HTTP POST, with a `data` argument which is a</span>
<span class="sd">    JSON-encoded dictionary of event data.</span>
<span class="sd">    If `send_as_json=True`, the content type of the request will be</span>
<span class="sd">    `&quot;application/json&quot;`.</span>
<span class="sd">    Otherwise the serialized JSON will be sent within a form.</span>

<span class="sd">    Args:</span>
<span class="sd">      root: String; root url of the target server.</span>
<span class="sd">      path: String; path relative to `root` to which the events will be sent.</span>
<span class="sd">      field: String; JSON field under which the data will be stored.</span>
<span class="sd">          The field is used only if the payload is sent within a form</span>
<span class="sd">          (i.e. send_as_json is set to False).</span>
<span class="sd">      headers: Dictionary; optional custom HTTP headers.</span>
<span class="sd">      send_as_json: Boolean; whether the request should be</span>
<span class="sd">          sent as `&quot;application/json&quot;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">root</span><span class="o">=</span><span class="s2">&quot;http://localhost:9000&quot;</span><span class="p">,</span>
        <span class="n">path</span><span class="o">=</span><span class="s2">&quot;/publish/epoch/end/&quot;</span><span class="p">,</span>
        <span class="n">field</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">send_as_json</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">root</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="n">field</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">send_as_json</span> <span class="o">=</span> <span class="n">send_as_json</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">requests</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;RemoteMonitor requires the `requests` library.&quot;</span><span class="p">)</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">send</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">send</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># np.ndarray and np.generic are not scalar types</span>
            <span class="c1"># therefore we must unwrap their scalar values and</span>
            <span class="c1"># pass to the json-serializable dict &#39;send&#39;</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">generic</span><span class="p">)):</span>
                <span class="n">send</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">send</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">send_as_json</span><span class="p">:</span>
                <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">send</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span>
                    <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">send</span><span class="p">)},</span>
                    <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Warning: could not reach RemoteMonitor root server at &quot;</span>
                <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">)</span>
            <span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.LearningRateScheduler&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LearningRateScheduler</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Learning rate scheduler.</span>

<span class="sd">    At the beginning of every epoch, this callback gets the updated learning</span>
<span class="sd">    rate value from `schedule` function provided at `__init__`, with the current</span>
<span class="sd">    epoch and current learning rate, and applies the updated learning rate on</span>
<span class="sd">    the optimizer.</span>

<span class="sd">    Args:</span>
<span class="sd">      schedule: a function that takes an epoch index (integer, indexed from 0)</span>
<span class="sd">          and current learning rate (float) as inputs and returns a new</span>
<span class="sd">          learning rate as output (float).</span>
<span class="sd">      verbose: int. 0: quiet, 1: update messages.</span>

<span class="sd">    Example:</span>

<span class="sd">    &gt;&gt;&gt; # This function keeps the initial learning rate for the first ten epochs</span>
<span class="sd">    &gt;&gt;&gt; # and decreases it exponentially after that.</span>
<span class="sd">    &gt;&gt;&gt; def scheduler(epoch, lr):</span>
<span class="sd">    ...   if epoch &lt; 10:</span>
<span class="sd">    ...     return lr</span>
<span class="sd">    ...   else:</span>
<span class="sd">    ...     return lr * tf.math.exp(-0.1)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])</span>
<span class="sd">    &gt;&gt;&gt; model.compile(tf.keras.optimizers.SGD(), loss=&#39;mse&#39;)</span>
<span class="sd">    &gt;&gt;&gt; round(model.optimizer.lr.numpy(), 5)</span>
<span class="sd">    0.01</span>

<span class="sd">    &gt;&gt;&gt; callback = tf.keras.callbacks.LearningRateScheduler(scheduler)</span>
<span class="sd">    &gt;&gt;&gt; history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),</span>
<span class="sd">    ...                     epochs=15, callbacks=[callback], verbose=0)</span>
<span class="sd">    &gt;&gt;&gt; round(model.optimizer.lr.numpy(), 5)</span>
<span class="sd">    0.00607</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">schedule</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span> <span class="o">=</span> <span class="n">schedule</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Optimizer must have a &quot;lr&quot; attribute.&#39;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>  <span class="c1"># new API</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">))</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>  <span class="c1"># Support for old API for backward compatibility</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;The output of the &quot;schedule&quot; function &#39;</span>
                <span class="sa">f</span><span class="s2">&quot;should be float. Got: </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">lr</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The dtype of `lr` Tensor should be float. Got: </span><span class="si">{</span><span class="n">lr</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">backend</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">lr</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">io_utils</span><span class="o">.</span><span class="n">print_msg</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: LearningRateScheduler setting learning &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;rate to </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">keras_model_summary</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Writes a Keras model as JSON to as a Summary.</span>

<span class="sd">    Writing the Keras model configuration allows the TensorBoard graph plugin to</span>
<span class="sd">    render a conceptual graph, as opposed to graph of ops. In case the model</span>
<span class="sd">    fails to serialize as JSON, it ignores and returns False.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: A name for this summary. The summary tag used for TensorBoard will</span>
<span class="sd">        be this name prefixed by any active name scopes.</span>
<span class="sd">      data: A Keras Model to write.</span>
<span class="sd">      step: Explicit `int64`-castable monotonic step value for this summary. If</span>
<span class="sd">        omitted, this defaults to `tf.summary.experimental.get_step()`, which</span>
<span class="sd">        must not be None.</span>

<span class="sd">    Returns:</span>
<span class="sd">      True on success, or False if no summary was written because no default</span>
<span class="sd">      summary writer was available.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: if a default writer exists, but no step was provided and</span>
<span class="sd">        `tf.summary.experimental.get_step()` is None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">summary_metadata</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">SummaryMetadata</span><span class="p">()</span>
    <span class="c1"># Hard coding a plugin name. Please refer to go/tb-plugin-name-hardcode for</span>
    <span class="c1"># the rationale.</span>
    <span class="n">summary_metadata</span><span class="o">.</span><span class="n">plugin_data</span><span class="o">.</span><span class="n">plugin_name</span> <span class="o">=</span> <span class="s2">&quot;graph_keras_model&quot;</span>
    <span class="c1"># version number = 1</span>
    <span class="n">summary_metadata</span><span class="o">.</span><span class="n">plugin_data</span><span class="o">.</span><span class="n">content</span> <span class="o">=</span> <span class="sa">b</span><span class="s2">&quot;1&quot;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">json_string</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_json</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
        <span class="c1"># An exception should not break a model code.</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Model failed to serialize as JSON. Ignoring... </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">exc</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">summary_scope</span><span class="p">(</span>
        <span class="n">name</span><span class="p">,</span> <span class="s2">&quot;graph_keras_model&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">step</span><span class="p">]</span>
    <span class="p">)</span> <span class="k">as</span> <span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu:0&quot;</span><span class="p">):</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">json_string</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
            <span class="n">tag</span><span class="o">=</span><span class="n">tag</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="n">summary_metadata</span>
        <span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.TensorBoard&quot;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[])</span>
<span class="k">class</span> <span class="nc">TensorBoard</span><span class="p">(</span><span class="n">Callback</span><span class="p">,</span> <span class="n">version_utils</span><span class="o">.</span><span class="n">TensorBoardVersionSelector</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Enable visualizations for TensorBoard.</span>

<span class="sd">    TensorBoard is a visualization tool provided with TensorFlow.</span>

<span class="sd">    This callback logs events for TensorBoard, including:</span>

<span class="sd">    * Metrics summary plots</span>
<span class="sd">    * Training graph visualization</span>
<span class="sd">    * Weight histograms</span>
<span class="sd">    * Sampled profiling</span>

<span class="sd">    When used in `Model.evaluate` or regular validation</span>
<span class="sd">    ([on_test_end](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_test_end)),</span>
<span class="sd">    in addition to epoch summaries, there will be a summary that records</span>
<span class="sd">    evaluation metrics vs `Model.optimizer.iterations` written. The metric names</span>
<span class="sd">    will be prepended with `evaluation`, with `Model.optimizer.iterations` being</span>
<span class="sd">    the step in the visualized TensorBoard.</span>

<span class="sd">    If you have installed TensorFlow with pip, you should be able</span>
<span class="sd">    to launch TensorBoard from the command line:</span>

<span class="sd">    ```</span>
<span class="sd">    tensorboard --logdir=path_to_your_logs</span>
<span class="sd">    ```</span>

<span class="sd">    You can find more information about TensorBoard</span>
<span class="sd">    [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).</span>

<span class="sd">    Args:</span>
<span class="sd">        log_dir: the path of the directory where to save the log files to be</span>
<span class="sd">          parsed by TensorBoard. e.g. log_dir = os.path.join(working_dir,</span>
<span class="sd">          &#39;logs&#39;) This directory should not be reused by any other callbacks.</span>
<span class="sd">        histogram_freq: frequency (in epochs) at which to compute</span>
<span class="sd">          weight histograms for the layers of the model. If set to 0, histograms</span>
<span class="sd">          won&#39;t be computed. Validation data (or split) must be specified for</span>
<span class="sd">          histogram visualizations.</span>
<span class="sd">        write_graph: whether to visualize the graph in TensorBoard. The log file</span>
<span class="sd">          can become quite large when write_graph is set to True.</span>
<span class="sd">        write_images: whether to write model weights to visualize as image in</span>
<span class="sd">          TensorBoard.</span>
<span class="sd">        write_steps_per_second: whether to log the training steps per second</span>
<span class="sd">          into TensorBoard. This supports both epoch and batch frequency</span>
<span class="sd">          logging.</span>
<span class="sd">        update_freq: `&#39;batch&#39;` or `&#39;epoch&#39;` or integer. When using `&#39;epoch&#39;`,</span>
<span class="sd">          writes the losses and metrics to TensorBoard after every epoch.</span>
<span class="sd">          If using an integer, let&#39;s say `1000`, all metrics and losses</span>
<span class="sd">          (including custom ones added by `Model.compile`) will be logged to</span>
<span class="sd">          TensorBoard every 1000 batches. `&#39;batch&#39;` is a synonym for `1`,</span>
<span class="sd">          meaning that they will be written every batch.</span>
<span class="sd">          Note however that writing too frequently to TensorBoard can slow down</span>
<span class="sd">          your training, especially when used with `tf.distribute.Strategy` as</span>
<span class="sd">          it will incur additional synchronization overhead.</span>
<span class="sd">          Use with `ParameterServerStrategy` is not supported.</span>
<span class="sd">          Batch-level summary writing is also available via `train_step`</span>
<span class="sd">          override. Please see</span>
<span class="sd">          [TensorBoard Scalars tutorial](https://www.tensorflow.org/tensorboard/scalars_and_keras#batch-level_logging)  # noqa: E501</span>
<span class="sd">          for more details.</span>
<span class="sd">        profile_batch: Profile the batch(es) to sample compute characteristics.</span>
<span class="sd">          profile_batch must be a non-negative integer or a tuple of integers.</span>
<span class="sd">          A pair of positive integers signify a range of batches to profile.</span>
<span class="sd">          By default, profiling is disabled.</span>
<span class="sd">        embeddings_freq: frequency (in epochs) at which embedding layers will be</span>
<span class="sd">          visualized. If set to 0, embeddings won&#39;t be visualized.</span>
<span class="sd">        embeddings_metadata: Dictionary which maps embedding layer names to the</span>
<span class="sd">          filename of a file in which to save metadata for the embedding layer.</span>
<span class="sd">          In case the same metadata file is to be</span>
<span class="sd">          used for all embedding layers, a single filename can be passed.</span>

<span class="sd">    Examples:</span>

<span class="sd">    Basic usage:</span>

<span class="sd">    ```python</span>
<span class="sd">    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=&quot;./logs&quot;)</span>
<span class="sd">    model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])</span>
<span class="sd">    # Then run the tensorboard command to view the visualizations.</span>
<span class="sd">    ```</span>

<span class="sd">    Custom batch-level summaries in a subclassed Model:</span>

<span class="sd">    ```python</span>
<span class="sd">    class MyModel(tf.keras.Model):</span>

<span class="sd">      def build(self, _):</span>
<span class="sd">        self.dense = tf.keras.layers.Dense(10)</span>

<span class="sd">      def call(self, x):</span>
<span class="sd">        outputs = self.dense(x)</span>
<span class="sd">        tf.summary.histogram(&#39;outputs&#39;, outputs)</span>
<span class="sd">        return outputs</span>

<span class="sd">    model = MyModel()</span>
<span class="sd">    model.compile(&#39;sgd&#39;, &#39;mse&#39;)</span>

<span class="sd">    # Make sure to set `update_freq=N` to log a batch-level summary every N</span>
<span class="sd">    # batches.  In addition to any `tf.summary` contained in `Model.call`,</span>
<span class="sd">    # metrics added in `Model.compile` will be logged every N batches.</span>
<span class="sd">    tb_callback = tf.keras.callbacks.TensorBoard(&#39;./logs&#39;, update_freq=1)</span>
<span class="sd">    model.fit(x_train, y_train, callbacks=[tb_callback])</span>
<span class="sd">    ```</span>

<span class="sd">    Custom batch-level summaries in a Functional API Model:</span>

<span class="sd">    ```python</span>
<span class="sd">    def my_summary(x):</span>
<span class="sd">      tf.summary.histogram(&#39;x&#39;, x)</span>
<span class="sd">      return x</span>

<span class="sd">    inputs = tf.keras.Input(10)</span>
<span class="sd">    x = tf.keras.layers.Dense(10)(inputs)</span>
<span class="sd">    outputs = tf.keras.layers.Lambda(my_summary)(x)</span>
<span class="sd">    model = tf.keras.Model(inputs, outputs)</span>
<span class="sd">    model.compile(&#39;sgd&#39;, &#39;mse&#39;)</span>

<span class="sd">    # Make sure to set `update_freq=N` to log a batch-level summary every N</span>
<span class="sd">    # batches. In addition to any `tf.summary` contained in `Model.call`,</span>
<span class="sd">    # metrics added in `Model.compile` will be logged every N batches.</span>
<span class="sd">    tb_callback = tf.keras.callbacks.TensorBoard(&#39;./logs&#39;, update_freq=1)</span>
<span class="sd">    model.fit(x_train, y_train, callbacks=[tb_callback])</span>
<span class="sd">    ```</span>

<span class="sd">    Profiling:</span>

<span class="sd">    ```python</span>
<span class="sd">    # Profile a single batch, e.g. the 5th batch.</span>
<span class="sd">    tensorboard_callback = tf.keras.callbacks.TensorBoard(</span>
<span class="sd">        log_dir=&#39;./logs&#39;, profile_batch=5)</span>
<span class="sd">    model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])</span>

<span class="sd">    # Profile a range of batches, e.g. from 10 to 20.</span>
<span class="sd">    tensorboard_callback = tf.keras.callbacks.TensorBoard(</span>
<span class="sd">        log_dir=&#39;./logs&#39;, profile_batch=(10,20))</span>
<span class="sd">    model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;logs&quot;</span><span class="p">,</span>
        <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">write_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">write_images</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">write_steps_per_second</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">update_freq</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
        <span class="n">profile_batch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">embeddings_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">embeddings_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_kwargs</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">io_utils</span><span class="o">.</span><span class="n">path_to_string</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="o">=</span> <span class="n">histogram_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_graph</span> <span class="o">=</span> <span class="n">write_graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_images</span> <span class="o">=</span> <span class="n">write_images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span> <span class="o">=</span> <span class="n">write_steps_per_second</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">update_freq</span> <span class="o">==</span> <span class="s2">&quot;batch&quot;</span> <span class="k">else</span> <span class="n">update_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="o">=</span> <span class="n">embeddings_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="o">=</span> <span class="n">embeddings_metadata</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_profile_batch</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_previous_epoch_iterations</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_accumulated_time</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Lazily initialized in order to avoid creating event files when</span>
        <span class="c1"># not needed.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Used to restore any existing `SummaryWriter` after training ends.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_state</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">_validate_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Handle arguments were supported in V1.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;write_grads&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;`write_grads` will be ignored in TensorFlow 2.0 &quot;</span>
                <span class="s2">&quot;for the `TensorBoard` Callback.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;`batch_size` is no longer needed in the &quot;</span>
                <span class="s2">&quot;`TensorBoard` Callback and will be ignored &quot;</span>
                <span class="s2">&quot;in TensorFlow 2.0.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;embeddings_layer_names&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;`embeddings_layer_names` is not supported in &quot;</span>
                <span class="s2">&quot;TensorFlow 2.0. Instead, all `Embedding` layers &quot;</span>
                <span class="s2">&quot;will be visualized.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;embeddings_data&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;`embeddings_data` is not supported in TensorFlow &quot;</span>
                <span class="s2">&quot;2.0. Instead, all `Embedding` variables will be &quot;</span>
                <span class="s2">&quot;visualized.&quot;</span>
            <span class="p">)</span>

        <span class="n">supported_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;write_grads&quot;</span><span class="p">,</span>
            <span class="s2">&quot;embeddings_layer_names&quot;</span><span class="p">,</span>
            <span class="s2">&quot;embeddings_data&quot;</span><span class="p">,</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">unrecognized_kwargs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="n">supported_kwargs</span>

        <span class="c1"># Only allow kwargs that were supported in V1.</span>
        <span class="k">if</span> <span class="n">unrecognized_kwargs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unrecognized arguments in `TensorBoard` Callback: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">unrecognized_kwargs</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Supported kwargs are: </span><span class="si">{</span><span class="n">supported_kwargs</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets Keras model and writes graph if specified.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_log_write_dir</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_train_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_train_counter</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_val_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_val_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_test_counter</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Resets writers.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_should_write_train_graph</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_graph</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_write_keras_model_summary</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_should_write_train_graph</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_configure_embeddings</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_train_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="s2">&quot;train&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_dir</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_val_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="s2">&quot;val&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_val_dir</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_get_log_write_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;For multi-worker, only chief should write, others write to &#39;/tmp&#39;.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">write_dirpath</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_delete_tmp_write_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Deletes tmp write directories for multi-worker.&quot;&quot;&quot;</span>
        <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">remove_temp_dirpath</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_write_keras_model_train_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes Keras model train_function graph to TensorBoard.&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">train_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train_tf_function</span>
                <span class="c1"># If the train_function is a `tf.function`, we can write out a</span>
                <span class="c1"># graph</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_fn</span><span class="p">,</span> <span class="s2">&quot;function_spec&quot;</span><span class="p">):</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">graph</span><span class="p">(</span>
                        <span class="n">train_fn</span><span class="o">.</span><span class="n">_concrete_variable_creation_fn</span><span class="o">.</span><span class="n">graph</span>
                    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_write_keras_model_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes Keras graph network summary to TensorBoard.&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">summary_writable</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_is_graph_network</span>
                    <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;Sequential&quot;</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">summary_writable</span><span class="p">:</span>
                    <span class="n">keras_model_summary</span><span class="p">(</span><span class="s2">&quot;keras&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_configure_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Configure the Projector for embeddings.&quot;&quot;&quot;</span>
        <span class="c1"># TODO(omalleyt): Add integration tests.</span>
        <span class="kn">from</span> <span class="nn">keras.src.layers</span> <span class="kn">import</span> <span class="n">core</span>
        <span class="kn">from</span> <span class="nn">keras.protobuf</span> <span class="kn">import</span> <span class="n">projector_config_pb2</span>

        <span class="c1"># isort: off</span>
        <span class="kn">from</span> <span class="nn">google.protobuf</span> <span class="kn">import</span> <span class="n">text_format</span>

        <span class="n">config</span> <span class="o">=</span> <span class="n">projector_config_pb2</span><span class="o">.</span><span class="n">ProjectorConfig</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">core</span><span class="o">.</span><span class="n">Embedding</span><span class="p">):</span>
                <span class="n">embedding</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
                <span class="c1"># Embeddings are always the first layer, so this naming should</span>
                <span class="c1"># be consistent in any keras models checkpoints.</span>
                <span class="n">name</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;layer_with_weights-0/embeddings/.ATTRIBUTES/VARIABLE_VALUE&quot;</span>
                <span class="p">)</span>
                <span class="n">embedding</span><span class="o">.</span><span class="n">tensor_name</span> <span class="o">=</span> <span class="n">name</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                            <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="p">,</span> <span class="nb">str</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unrecognized `Embedding` layer names passed to &quot;</span>
                <span class="s2">&quot;`keras.callbacks.TensorBoard` `embeddings_metadata` &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;argument: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">config_pbtxt</span> <span class="o">=</span> <span class="n">text_format</span><span class="o">.</span><span class="n">MessageToString</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="s2">&quot;projector_config.pbtxt&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">config_pbtxt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_push_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the default writer for custom batch-level summaries.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">==</span> <span class="s2">&quot;epoch&quot;</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">should_record</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="c1"># TODO(b/151339474): Fix deadlock when not using .value() here.</span>
        <span class="n">summary_context</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">(</span><span class="n">step</span><span class="o">.</span><span class="n">value</span><span class="p">()),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="n">should_record</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">summary_context</span><span class="p">)</span>
        <span class="n">summary_context</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>
        <span class="n">summary_context</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_pop_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pops the current writer.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">==</span> <span class="s2">&quot;epoch&quot;</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># See _push_writer for the content of the previous_context, which is</span>
        <span class="c1"># pair of context.</span>
        <span class="n">previous_context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_state</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
        <span class="n">previous_context</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="o">*</span><span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">())</span>
        <span class="n">previous_context</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="o">*</span><span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_close_writers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">writer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_init_profile_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">profile_batch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate profile_batch value and set the range of batches to profile.</span>

<span class="sd">        Sets values of _start_batch and _stop_batch attributes,</span>
<span class="sd">        specifying the start and stop batch to profile.</span>
<span class="sd">        Setting `profile_batch=0` disables profiling.</span>

<span class="sd">        Args:</span>
<span class="sd">          profile_batch: The range of batches to profile. Should be a</span>
<span class="sd">            non-negative integer or a comma separated string of pair of positive</span>
<span class="sd">            integers. A pair of positive integers signify a range of batches to</span>
<span class="sd">            profile.</span>

<span class="sd">        Raises:</span>
<span class="sd">          ValueError: If profile_batch is not an integer or a comma separated</span>
<span class="sd">            pair of positive integers.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">profile_batch_error_message</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;profile_batch must be a non-negative integer or &quot;</span>
            <span class="s2">&quot;2-tuple of positive &quot;</span>
            <span class="s2">&quot;integers. A pair of positive integers &quot;</span>
            <span class="s2">&quot;signifies a range of batches &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;to profile. Found: </span><span class="si">{</span><span class="n">profile_batch</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Support legacy way of specifying &quot;start,stop&quot; or &quot;start&quot; as str.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">profile_batch</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
            <span class="n">profile_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">profile_batch</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span> <span class="o">=</span> <span class="n">profile_batch</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span> <span class="o">=</span> <span class="n">profile_batch</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span> <span class="o">=</span> <span class="n">profile_batch</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">profile_batch_error_message</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">profile_batch_error_message</span><span class="p">)</span>

        <span class="c1"># True when the profiler was successfully started by this callback.</span>
        <span class="c1"># We track the status here to make sure callbacks do not interfere with</span>
        <span class="c1"># each other. The callback will only stop the profiler it started.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Warm up and improve the profiling accuracy.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_start_profiler</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stop_profiler</span><span class="p">(</span><span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># True when a trace is running.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Setting `profile_batch=0` disables profiling.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_should_trace</span> <span class="o">=</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_previous_epoch_iterations</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_push_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pop_writer</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stop_trace</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_close_writers</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delete_tmp_write_dir</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_push_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_val_writer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_step</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;iterations&quot;</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
                        <span class="s2">&quot;evaluation_&quot;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_vs_iterations&quot;</span><span class="p">,</span>
                        <span class="n">value</span><span class="p">,</span>
                        <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">read_value</span><span class="p">(),</span>
                    <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pop_writer</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_implements_train_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Only call batch hooks when tracing or write_steps_per_second are</span>
        <span class="c1"># enabled</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_trace</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span>

    <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_trace</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_start_trace</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_write_train_graph</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_write_keras_model_train_graph</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_should_write_train_graph</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span><span class="p">:</span>
            <span class="n">batch_run_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
                <span class="s2">&quot;batch_steps_per_second&quot;</span><span class="p">,</span>
                <span class="mf">1.0</span> <span class="o">/</span> <span class="n">batch_run_time</span><span class="p">,</span>
                <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># `logs` isn&#39;t necessarily always a dict. For example, when using</span>
        <span class="c1"># `tf.distribute.experimental.ParameterServerStrategy`, a</span>
        <span class="c1"># `tf.distribute.experimental.coordinator.RemoteValue` will be passed.</span>
        <span class="c1"># For now, we just disable `update_freq` in those cases.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;batch_&quot;</span> <span class="o">+</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_trace</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stop_trace</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Keeps track of epoch for profiling.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_previous_epoch_iterations</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_epoch_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Runs metrics and histogram summaries at epoch end.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_epoch_metrics</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_weights</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_embeddings</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_start_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">trace_on</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">profiler</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_start_profiler</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_stop_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Logs the trace graph to TensorBoard.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="c1"># TODO(b/126388999): Remove step info in the summary name.</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">trace_export</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;batch_</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">batch</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stop_profiler</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_collect_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
            <span class="n">lr_schedule</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;_learning_rate&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lr_schedule</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr_schedule</span><span class="p">,</span> <span class="n">learning_rate_schedule</span><span class="o">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
            <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_schedule</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logs</span>

    <span class="k">def</span> <span class="nf">_compute_steps_per_second</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">current_iteration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">time_since_epoch_begin</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epoch_start_time</span>
        <span class="n">steps_per_second</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">current_iteration</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_previous_epoch_iterations</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">time_since_epoch_begin</span>
        <span class="k">return</span> <span class="n">steps_per_second</span>

    <span class="k">def</span> <span class="nf">_log_epoch_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes epoch metrics out as scalar summaries.</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch: Int. The global step to use for TensorBoard.</span>
<span class="sd">            logs: Dict. Keys are scalar summary names, values are scalars.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">logs</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">train_logs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">val_logs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;val_&quot;</span><span class="p">):</span>
                <span class="n">val_logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">train_logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="n">train_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_collect_learning_rate</span><span class="p">(</span><span class="n">train_logs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span><span class="p">:</span>
            <span class="n">train_logs</span><span class="p">[</span><span class="s2">&quot;steps_per_second&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_steps_per_second</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">train_logs</span><span class="p">:</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">train_logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;epoch_&quot;</span> <span class="o">+</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">val_logs</span><span class="p">:</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="mi">4</span><span class="p">:]</span>  <span class="c1"># Remove &#39;val_&#39; prefix.</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;epoch_&quot;</span> <span class="o">+</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_log_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Logs the weights of the Model to TensorBoard.&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
                        <span class="n">weight_name</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="p">)</span>
                        <span class="c1"># Add a suffix to prevent summary tag name collision.</span>
                        <span class="n">histogram_weight_name</span> <span class="o">=</span> <span class="n">weight_name</span> <span class="o">+</span> <span class="s2">&quot;/histogram&quot;</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span>
                            <span class="n">histogram_weight_name</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_images</span><span class="p">:</span>
                            <span class="c1"># Add a suffix to prevent summary tag name</span>
                            <span class="c1"># collision.</span>
                            <span class="n">image_weight_name</span> <span class="o">=</span> <span class="n">weight_name</span> <span class="o">+</span> <span class="s2">&quot;/image&quot;</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_log_weight_as_image</span><span class="p">(</span>
                                <span class="n">weight</span><span class="p">,</span> <span class="n">image_weight_name</span><span class="p">,</span> <span class="n">epoch</span>
                            <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_log_weight_as_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Logs a weight as a TensorBoard image.&quot;&quot;&quot;</span>
        <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Bias case</span>
            <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Dense layer kernel case</span>
            <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
            <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># ConvNet case</span>
            <span class="k">if</span> <span class="n">backend</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;channels_last&quot;</span><span class="p">:</span>
                <span class="c1"># Switch to channels_first to display every kernel as a separate</span>
                <span class="c1"># image.</span>
                <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
            <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>

        <span class="n">shape</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
        <span class="c1"># Not possible to handle 3D convnets etc.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span> <span class="ow">and</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="n">weight_name</span><span class="p">,</span> <span class="n">w_img</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_log_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="n">embeddings_ckpt</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span>
            <span class="s2">&quot;train&quot;</span><span class="p">,</span>
            <span class="sa">f</span><span class="s2">&quot;keras_embedding.ckpt-</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">embeddings_ckpt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_start_profiler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logdir</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Starts the profiler if currently inactive.</span>

<span class="sd">        Args:</span>
<span class="sd">          logdir: Directory where profiler results will be saved.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="n">logdir</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">AlreadyExistsError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># Profiler errors should not be fatal.</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Failed to start profiler: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_stop_profiler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Stops the profiler if currently active.</span>

<span class="sd">        Args:</span>
<span class="sd">          save: Whether to save the profiler results to TensorBoard.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="n">save</span><span class="o">=</span><span class="n">save</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">UnavailableError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># Profiler errors should not be fatal.</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Failed to stop profiler: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span> <span class="o">=</span> <span class="kc">False</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.ReduceLROnPlateau&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ReduceLROnPlateau</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reduce learning rate when a metric has stopped improving.</span>

<span class="sd">    Models often benefit from reducing the learning rate by a factor</span>
<span class="sd">    of 2-10 once learning stagnates. This callback monitors a</span>
<span class="sd">    quantity and if no improvement is seen for a &#39;patience&#39; number</span>
<span class="sd">    of epochs, the learning rate is reduced.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    reduce_lr = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.2,</span>
<span class="sd">                                  patience=5, min_lr=0.001)</span>
<span class="sd">    model.fit(X_train, Y_train, callbacks=[reduce_lr])</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">        monitor: quantity to be monitored.</span>
<span class="sd">        factor: factor by which the learning rate will be reduced.</span>
<span class="sd">          `new_lr = lr * factor`.</span>
<span class="sd">        patience: number of epochs with no improvement after which learning rate</span>
<span class="sd">          will be reduced.</span>
<span class="sd">        verbose: int. 0: quiet, 1: update messages.</span>
<span class="sd">        mode: one of `{&#39;auto&#39;, &#39;min&#39;, &#39;max&#39;}`. In `&#39;min&#39;` mode,</span>
<span class="sd">          the learning rate will be reduced when the</span>
<span class="sd">          quantity monitored has stopped decreasing; in `&#39;max&#39;` mode it will be</span>
<span class="sd">          reduced when the quantity monitored has stopped increasing; in</span>
<span class="sd">          `&#39;auto&#39;` mode, the direction is automatically inferred from the name</span>
<span class="sd">          of the monitored quantity.</span>
<span class="sd">        min_delta: threshold for measuring the new optimum, to only focus on</span>
<span class="sd">          significant changes.</span>
<span class="sd">        cooldown: number of epochs to wait before resuming normal operation</span>
<span class="sd">          after lr has been reduced.</span>
<span class="sd">        min_lr: lower bound on the learning rate.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
        <span class="n">factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">min_delta</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">cooldown</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">min_lr</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
        <span class="k">if</span> <span class="n">factor</span> <span class="o">&gt;=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;ReduceLROnPlateau does not support &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;a factor &gt;= 1.0. Got </span><span class="si">{</span><span class="n">factor</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;epsilon&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">min_delta</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;epsilon&quot;</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;`epsilon` argument is deprecated and &quot;</span>
                <span class="s2">&quot;will be removed, use `min_delta` instead.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">factor</span> <span class="o">=</span> <span class="n">factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span> <span class="o">=</span> <span class="n">min_lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="n">min_delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cooldown</span> <span class="o">=</span> <span class="n">cooldown</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Cooldown counter.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets wait counter and cooldown counter.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">]:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Learning rate reduction mode </span><span class="si">%s</span><span class="s2"> is unknown, &quot;</span>
                <span class="s2">&quot;fallback to auto mode.&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span> <span class="ow">and</span> <span class="s2">&quot;acc&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
        <span class="n">current</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Learning rate reduction is conditioned on metric `</span><span class="si">%s</span><span class="s2">` &quot;</span>
                <span class="s2">&quot;which is not available. Available metrics are: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span>
                <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())),</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_cooldown</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">-=</span> <span class="mi">1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_cooldown</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                    <span class="n">old_lr</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">old_lr</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">):</span>
                        <span class="n">new_lr</span> <span class="o">=</span> <span class="n">old_lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">factor</span>
                        <span class="n">new_lr</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">new_lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">)</span>
                        <span class="n">backend</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">new_lr</span><span class="p">)</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">io_utils</span><span class="o">.</span><span class="n">print_msg</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: &quot;</span>
                                <span class="s2">&quot;ReduceLROnPlateau reducing &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;learning rate to </span><span class="si">{</span><span class="n">new_lr</span><span class="si">}</span><span class="s2">.&quot;</span>
                            <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooldown</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">in_cooldown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">&gt;</span> <span class="mi">0</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.CSVLogger&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CSVLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback that streams epoch results to a CSV file.</span>

<span class="sd">    Supports all values that can be represented as a string,</span>
<span class="sd">    including 1D iterables such as `np.ndarray`.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    csv_logger = CSVLogger(&#39;training.log&#39;)</span>
<span class="sd">    model.fit(X_train, Y_train, callbacks=[csv_logger])</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">        filename: Filename of the CSV file, e.g. `&#39;run/log.csv&#39;`.</span>
<span class="sd">        separator: String used to separate elements in the CSV file.</span>
<span class="sd">        append: Boolean. True: append if file exists (useful for continuing</span>
<span class="sd">            training). False: overwrite existing file.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">separator</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sep</span> <span class="o">=</span> <span class="n">separator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">io_utils</span><span class="o">.</span><span class="n">path_to_string</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">append</span> <span class="o">=</span> <span class="n">append</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">bool</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()))</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;a&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;w&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>

        <span class="k">def</span> <span class="nf">handle_value</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="n">is_zero_dim_ndarray</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">k</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">k</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">abc</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_zero_dim_ndarray</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">[</span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="p">))</span><span class="si">}</span><span class="s2">]</span><span class="se">\&quot;</span><span class="s2">&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">k</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="c1"># When validation_freq &gt; 1, `val_` keys are not in first epoch logs</span>
            <span class="c1"># Add the `val_` keys so that its part of the fieldnames of writer.</span>
            <span class="n">val_keys_found</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;val_&quot;</span><span class="p">):</span>
                    <span class="n">val_keys_found</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">val_keys_found</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s2">&quot;val_&quot;</span> <span class="o">+</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">])</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>

            <span class="k">class</span> <span class="nc">CustomDialect</span><span class="p">(</span><span class="n">csv</span><span class="o">.</span><span class="n">excel</span><span class="p">):</span>
                <span class="n">delimiter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sep</span>

            <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">,</span> <span class="n">dialect</span><span class="o">=</span><span class="n">CustomDialect</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

        <span class="n">row_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">})</span>
        <span class="n">row_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">handle_value</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;NA&quot;</span><span class="p">)))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">row_dict</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s2">&quot;keras.callbacks.LambdaCallback&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LambdaCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Callback for creating simple, custom callbacks on-the-fly.</span>

<span class="sd">    This callback is constructed with anonymous functions that will be called</span>
<span class="sd">    at the appropriate time (during `Model.{fit | evaluate | predict}`).</span>
<span class="sd">    Note that the callbacks expects positional arguments, as:</span>

<span class="sd">    - `on_epoch_begin` and `on_epoch_end` expect two positional arguments:</span>
<span class="sd">      `epoch`, `logs`</span>
<span class="sd">    - `on_batch_begin` and `on_batch_end` expect two positional arguments:</span>
<span class="sd">      `batch`, `logs`</span>
<span class="sd">    - `on_train_begin` and `on_train_end` expect one positional argument:</span>
<span class="sd">      `logs`</span>

<span class="sd">    Args:</span>
<span class="sd">        on_epoch_begin: called at the beginning of every epoch.</span>
<span class="sd">        on_epoch_end: called at the end of every epoch.</span>
<span class="sd">        on_batch_begin: called at the beginning of every batch.</span>
<span class="sd">        on_batch_end: called at the end of every batch.</span>
<span class="sd">        on_train_begin: called at the beginning of model training.</span>
<span class="sd">        on_train_end: called at the end of model training.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    # Print the batch number at the beginning of every batch.</span>
<span class="sd">    batch_print_callback = LambdaCallback(</span>
<span class="sd">        on_batch_begin=lambda batch,logs: print(batch))</span>

<span class="sd">    # Stream the epoch loss to a file in JSON format. The file content</span>
<span class="sd">    # is not well-formed JSON but rather has a JSON object per line.</span>
<span class="sd">    import json</span>
<span class="sd">    json_log = open(&#39;loss_log.json&#39;, mode=&#39;wt&#39;, buffering=1)</span>
<span class="sd">    json_logging_callback = LambdaCallback(</span>
<span class="sd">        on_epoch_end=lambda epoch, logs: json_log.write(</span>
<span class="sd">            json.dumps({&#39;epoch&#39;: epoch, &#39;loss&#39;: logs[&#39;loss&#39;]}) + &#39;\n&#39;),</span>
<span class="sd">        on_train_end=lambda logs: json_log.close()</span>
<span class="sd">    )</span>

<span class="sd">    # Terminate some processes after having finished model training.</span>
<span class="sd">    processes = ...</span>
<span class="sd">    cleanup_callback = LambdaCallback(</span>
<span class="sd">        on_train_end=lambda logs: [</span>
<span class="sd">            p.terminate() for p in processes if p.is_alive()])</span>

<span class="sd">    model.fit(...,</span>
<span class="sd">              callbacks=[batch_print_callback,</span>
<span class="sd">                         json_logging_callback,</span>
<span class="sd">                         cleanup_callback])</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">on_epoch_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">on_epoch_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">on_batch_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">on_batch_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">on_train_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">on_train_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">on_epoch_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_begin</span> <span class="o">=</span> <span class="n">on_epoch_begin</span>
        <span class="k">if</span> <span class="n">on_epoch_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_end</span> <span class="o">=</span> <span class="n">on_epoch_end</span>
        <span class="k">if</span> <span class="n">on_batch_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span> <span class="o">=</span> <span class="n">on_batch_begin</span>
        <span class="k">if</span> <span class="n">on_batch_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span> <span class="o">=</span> <span class="n">on_batch_end</span>
        <span class="k">if</span> <span class="n">on_train_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span> <span class="o">=</span> <span class="n">on_train_begin</span>
        <span class="k">if</span> <span class="n">on_train_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span> <span class="o">=</span> <span class="n">on_train_end</span>

</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Erick Matsen
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
       Copyright 2022, Erick Matsen.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>