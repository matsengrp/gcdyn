{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gcdyn.deeplearning import NeuralNetworkModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"merged-simu.pkl\", \"rb\") as f:\n",
    "    samples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetworkModel(samples[\"trees\"], samples[\"responses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(model.trees, ladderize_trees=False)\n",
    "predicted_constants = np.array([row[1].value for row in result])\n",
    "\n",
    "constants = np.array([row[1].value for row in samples[\"responses\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.24212786708419"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((predicted_constants - constants) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:43:44.772491: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2s 41ms/step - loss: 1713.0304\n",
      "Epoch 2/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 1466.1598\n",
      "Epoch 3/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1379.1154\n",
      "Epoch 4/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1322.7710\n",
      "Epoch 5/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1269.1360\n",
      "Epoch 6/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1290.5397\n",
      "Epoch 7/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1253.0452\n",
      "Epoch 8/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1244.7930\n",
      "Epoch 9/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1253.4261\n",
      "Epoch 10/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1242.9186\n",
      "Epoch 11/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1242.3795\n",
      "Epoch 12/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1259.6632\n",
      "Epoch 13/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1224.3657\n",
      "Epoch 14/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1245.2422\n",
      "Epoch 15/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1256.1803\n",
      "Epoch 16/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1216.7114\n",
      "Epoch 17/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1224.0232\n",
      "Epoch 18/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 1234.8053\n",
      "Epoch 19/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 1232.3322\n",
      "Epoch 20/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1231.5409\n",
      "Epoch 21/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 1226.5475\n",
      "Epoch 22/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1203.8369\n",
      "Epoch 23/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1216.5823\n",
      "Epoch 24/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 1240.4802\n",
      "Epoch 25/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 1209.8433\n",
      "Epoch 26/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1221.8452\n",
      "Epoch 27/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1209.0074\n",
      "Epoch 28/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 1207.9172\n",
      "Epoch 29/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1198.0782\n",
      "Epoch 30/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1196.9691\n",
      "Epoch 31/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1172.1647\n",
      "Epoch 32/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1193.5326\n",
      "Epoch 33/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 1164.8065\n",
      "Epoch 34/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 1179.9437\n",
      "Epoch 35/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 1148.2544\n",
      "Epoch 36/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1164.6460\n",
      "Epoch 37/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 1130.0090\n",
      "Epoch 38/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1156.9229\n",
      "Epoch 39/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1127.5165\n",
      "Epoch 40/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1121.0883\n",
      "Epoch 41/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 1069.6897\n",
      "Epoch 42/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1113.4241\n",
      "Epoch 43/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 1119.6541\n",
      "Epoch 44/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 1055.5483\n",
      "Epoch 45/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 1068.5481\n",
      "Epoch 46/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 1044.8638\n",
      "Epoch 47/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 1017.9424\n",
      "Epoch 48/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1069.5703\n",
      "Epoch 49/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 975.5766\n",
      "Epoch 50/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 999.0756\n",
      "Epoch 51/200\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 944.8545\n",
      "Epoch 52/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 950.6863\n",
      "Epoch 53/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 945.5886\n",
      "Epoch 54/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 901.2142\n",
      "Epoch 55/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 943.6454\n",
      "Epoch 56/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 870.1520\n",
      "Epoch 57/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 878.2111\n",
      "Epoch 58/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 859.4073\n",
      "Epoch 59/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 856.6193\n",
      "Epoch 60/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 812.2785\n",
      "Epoch 61/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 806.9070\n",
      "Epoch 62/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 793.2990\n",
      "Epoch 63/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 751.4218\n",
      "Epoch 64/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 690.4119\n",
      "Epoch 65/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 791.2302\n",
      "Epoch 66/200\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 623.8175\n",
      "Epoch 67/200\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 721.4041\n",
      "Epoch 68/200\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 618.6379\n",
      "Epoch 69/200\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 626.8406\n",
      "Epoch 70/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 669.5128\n",
      "Epoch 71/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 516.0415\n",
      "Epoch 72/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 555.9152\n",
      "Epoch 73/200\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 537.2695\n",
      "Epoch 74/200\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 597.2249\n",
      "Epoch 75/200\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 484.0049\n",
      "Epoch 76/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 540.3702\n",
      "Epoch 77/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 436.4458\n",
      "Epoch 78/200\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 525.5217\n",
      "Epoch 79/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 452.8085\n",
      "Epoch 80/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 459.0303\n",
      "Epoch 81/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 469.6959\n",
      "Epoch 82/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 435.4501\n",
      "Epoch 83/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 363.3857\n",
      "Epoch 84/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 405.7384\n",
      "Epoch 85/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 349.2990\n",
      "Epoch 86/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 339.5675\n",
      "Epoch 87/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 387.1205\n",
      "Epoch 88/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 388.1632\n",
      "Epoch 89/200\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 307.1373\n",
      "Epoch 90/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 367.8899\n",
      "Epoch 91/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 228.3338\n",
      "Epoch 92/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 308.1497\n",
      "Epoch 93/200\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 249.6761\n",
      "Epoch 94/200\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 296.1550\n",
      "Epoch 95/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 247.0063\n",
      "Epoch 96/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 238.5859\n",
      "Epoch 97/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 237.6143\n",
      "Epoch 98/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 233.6379\n",
      "Epoch 99/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 232.1187\n",
      "Epoch 100/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 211.5376\n",
      "Epoch 101/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 219.0164\n",
      "Epoch 102/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 174.0397\n",
      "Epoch 103/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 264.7347\n",
      "Epoch 104/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 192.3891\n",
      "Epoch 105/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 137.5575\n",
      "Epoch 106/200\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 219.6370\n",
      "Epoch 107/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 178.8169\n",
      "Epoch 108/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 156.5499\n",
      "Epoch 109/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 182.6983\n",
      "Epoch 110/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 160.2092\n",
      "Epoch 111/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 166.0274\n",
      "Epoch 112/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 174.2843\n",
      "Epoch 113/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 124.5822\n",
      "Epoch 114/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 174.2388\n",
      "Epoch 115/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 135.1419\n",
      "Epoch 116/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 161.1886\n",
      "Epoch 117/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 92.9864\n",
      "Epoch 118/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 141.4986\n",
      "Epoch 119/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 137.7077\n",
      "Epoch 120/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 153.0461\n",
      "Epoch 121/200\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 140.4614\n",
      "Epoch 122/200\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 103.3916\n",
      "Epoch 123/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 153.8069\n",
      "Epoch 124/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 109.4397\n",
      "Epoch 125/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 169.7259\n",
      "Epoch 126/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 72.8521\n",
      "Epoch 127/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 139.4273\n",
      "Epoch 128/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 137.1118\n",
      "Epoch 129/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 96.3663\n",
      "Epoch 130/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 109.5142\n",
      "Epoch 131/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 117.9466\n",
      "Epoch 132/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 102.9672\n",
      "Epoch 133/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 107.2247\n",
      "Epoch 134/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 104.7021\n",
      "Epoch 135/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 88.7482\n",
      "Epoch 136/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 112.0765\n",
      "Epoch 137/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 84.9930\n",
      "Epoch 138/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 84.9203\n",
      "Epoch 139/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 100.5610\n",
      "Epoch 140/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 72.0803\n",
      "Epoch 141/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 102.9133\n",
      "Epoch 142/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 97.6012\n",
      "Epoch 143/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 74.1528\n",
      "Epoch 144/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 92.2464\n",
      "Epoch 145/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 77.5031\n",
      "Epoch 146/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 106.2613\n",
      "Epoch 147/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 67.4669\n",
      "Epoch 148/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 129.7753\n",
      "Epoch 149/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 56.9484\n",
      "Epoch 150/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 76.9708\n",
      "Epoch 151/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 75.5095\n",
      "Epoch 152/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 92.2548\n",
      "Epoch 153/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 60.7380\n",
      "Epoch 154/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 74.4351\n",
      "Epoch 155/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 58.2016\n",
      "Epoch 156/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 76.9666\n",
      "Epoch 157/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 48.7966\n",
      "Epoch 158/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 58.6361\n",
      "Epoch 159/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 80.9151\n",
      "Epoch 160/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 61.4484\n",
      "Epoch 161/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 59.3231\n",
      "Epoch 162/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 80.2908\n",
      "Epoch 163/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 57.7689\n",
      "Epoch 164/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 68.6129\n",
      "Epoch 165/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 63.4873\n",
      "Epoch 166/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 57.6837\n",
      "Epoch 167/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 52.2329\n",
      "Epoch 168/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 55.4500\n",
      "Epoch 169/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 60.9038\n",
      "Epoch 170/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 52.5280\n",
      "Epoch 171/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 63.7251\n",
      "Epoch 172/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 48.9630\n",
      "Epoch 173/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 48.5173\n",
      "Epoch 174/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 62.5019\n",
      "Epoch 175/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 38.7758\n",
      "Epoch 176/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 62.4176\n",
      "Epoch 177/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 29.0940\n",
      "Epoch 178/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 39.8982\n",
      "Epoch 179/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 51.4257\n",
      "Epoch 180/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 49.0435\n",
      "Epoch 181/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 35.8774\n",
      "Epoch 182/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 56.4715\n",
      "Epoch 183/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 38.2562\n",
      "Epoch 184/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 30.4974\n",
      "Epoch 185/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 51.3560\n",
      "Epoch 186/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 34.9568\n",
      "Epoch 187/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 42.1745\n",
      "Epoch 188/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 28.4773\n",
      "Epoch 189/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 52.7505\n",
      "Epoch 190/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 28.1545\n",
      "Epoch 191/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 35.6113\n",
      "Epoch 192/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 35.1326\n",
      "Epoch 193/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 28.4356\n",
      "Epoch 194/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 34.7175\n",
      "Epoch 195/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 23.8375\n",
      "Epoch 196/200\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 30.4478\n",
      "Epoch 197/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 50.0922\n",
      "Epoch 198/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 13.0884\n",
      "Epoch 199/200\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 25.2960\n",
      "Epoch 200/200\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 28.7995\n"
     ]
    }
   ],
   "source": [
    "model.fit(epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477.2903397324176"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(model.trees, ladderize_trees=False)\n",
    "predicted_constants = np.array([row[1].value for row in result])\n",
    "\n",
    "sum((predicted_constants - constants) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9988546 , -0.56473744,  0.2979228 , -0.9897843 , -0.9843863 ,\n",
       "       -0.95933926, -0.98706365, -0.24939787, -0.9812735 , -0.9823739 ,\n",
       "       -0.91822016, -0.96630454, -0.88172746, -0.8027267 , -0.69958746,\n",
       "       -0.9365197 , -0.66604984, -0.94891   , -0.93353873, -0.9991246 ,\n",
       "       -0.9370747 , -0.83880454, -0.9159542 , -0.96050566, -0.9863038 ,\n",
       "       -0.9664683 , -0.99606675, -0.8789443 , -0.998946  , -0.71225506,\n",
       "       -0.52653027, -0.8993547 , -0.9973387 , -0.984906  , -0.9979346 ,\n",
       "       -0.9975682 , -0.9187318 , -0.8942697 , -0.96916175, -0.98585874,\n",
       "       -0.99730664, -0.988591  , -0.9889501 , -0.9477886 , -0.94817173,\n",
       "       -0.9858106 , -0.99813896, -0.89982414, -0.61716574, -0.96497536,\n",
       "       -0.99608177, -0.9755797 , -0.76987046, -0.9300983 , -0.80424684,\n",
       "       -0.9896581 , -0.99567395, -0.86590433, -0.81948036, -0.3155887 ,\n",
       "       -0.86417794, -0.87041456,  0.31806034, -0.9484537 ,  0.33150548,\n",
       "       -0.76727927, -0.5257441 , -0.08105916, -0.99190825, -0.8046239 ,\n",
       "       -0.45827425, -0.83917   , -0.87577105,  0.41273373, -0.8056694 ,\n",
       "       -0.6370294 , -0.9987231 , -0.27253067, -0.78789353, -0.27169627,\n",
       "       -0.7745315 , -0.86606896, -0.82885057, -0.89469355, -0.7025208 ,\n",
       "       -0.937648  , -0.7150042 , -0.9760939 , -0.6762639 , -0.99660677,\n",
       "       -0.9960386 , -0.9919284 , -0.98483276, -0.92722374, -0.75787777,\n",
       "       -0.99429554, -0.89803   , -0.90489644,  1.556382  , -0.9901221 ,\n",
       "       -0.81035537, -0.9608511 , -0.9828689 , -0.9968824 , -0.6023407 ,\n",
       "       -0.77139366, -0.95648134, -0.9559887 , -0.9420568 , -0.824749  ,\n",
       "       -0.84457904, -0.82603395, -0.9961191 , -0.99206793, -0.9886054 ,\n",
       "       -0.9955303 , -0.9964185 , -0.7931423 , -0.98795015, -0.9888845 ,\n",
       "       -0.9733217 , -0.9723295 , -0.76890254, -0.934573  , -0.8214653 ,\n",
       "       -0.946435  , -0.96579576, -0.99860305, -0.5065229 ,  1.9051092 ,\n",
       "       -0.8532864 , -0.6747108 , -0.9904957 , -0.99915457, -0.99875706,\n",
       "       -0.57007074, -0.9055072 , -0.77225494, -0.99838483, -0.9722338 ,\n",
       "       -0.7453231 , -0.8271276 , -0.9920313 , -0.7258211 , -0.87313443,\n",
       "       -0.99775994, -0.66439253, -0.8791629 , -0.45903307, -0.9597258 ,\n",
       "       -0.9955067 , -0.94008493, -0.993005  , -0.9994283 , -0.87460715,\n",
       "       -0.9990811 , -0.99987406, -0.9977239 , -0.99955434, -0.9968451 ,\n",
       "       -0.9867455 , -0.99942094, -0.814434  , -0.9998936 , -0.99923325,\n",
       "       -0.9902835 , -0.9985334 , -0.83823806, -0.9994495 , -0.995343  ,\n",
       "       -0.80326295, -0.9998572 , -0.74763954, -0.99984604, -0.999827  ,\n",
       "       -0.99988747, -0.9973336 , -0.98348516, -0.9120706 , -0.9998773 ,\n",
       "       -0.9987858 , -0.7491975 , -0.99462956, -0.99297553, -0.8173912 ,\n",
       "       -0.9997571 , -0.7874586 , -0.999966  , -0.9204897 , -0.99820435,\n",
       "       -0.99989456, -0.9981781 , -0.99907994, -0.99948835, -0.9991885 ,\n",
       "       -0.80584264, -0.9996732 , -0.99904984, -0.9989539 , -0.99757004,\n",
       "       -0.98725224, -0.999265  , -0.99980766, -0.9997883 , -0.85158056,\n",
       "       -0.980816  , -0.99404424,  0.7329244 ,  0.20731038, -0.86527514,\n",
       "       -0.4243825 , -0.7873806 , -0.9734749 , -0.9574666 , -0.9432235 ,\n",
       "        0.6536655 , -0.86075413, -0.9604418 , -0.32013106, -0.8241015 ,\n",
       "       -0.6675567 , -0.9125771 , -0.6031414 , -0.91392463, -0.7767869 ,\n",
       "       -0.9514662 , -0.44686627, -0.8173815 , -0.37674785, -0.6303592 ,\n",
       "       -0.8764178 , -0.99398136, -0.9327212 , -0.92441815, -0.5769209 ,\n",
       "        0.38869518, -0.6876095 , -0.874083  , -0.28358537,  0.04940218,\n",
       "       -0.9265678 , -0.99936306,  0.7684874 , -0.5013101 , -0.8169566 ,\n",
       "       -0.8644626 , -0.9339361 , -0.6352176 , -0.34804285,  1.047543  ,\n",
       "       -0.77677846, -0.70379794, -0.10238254,  1.5480652 , -0.8954657 ,\n",
       "       -0.37328732, -0.9995804 , -0.8562882 , -0.184659  , -0.6557103 ,\n",
       "       -0.86133146, -0.17236245, -0.51538664, -0.62465656, -0.16216958,\n",
       "       -0.7056489 , -0.78607076, -0.7797315 , -0.71344435, -0.83388096,\n",
       "       -0.9933101 , -0.66025305, -0.9537221 , -0.9990984 , -0.7013788 ,\n",
       "       -0.4700687 , -0.6650342 , -0.6127193 , -0.804513  , -0.6097062 ,\n",
       "       -0.33262026, -0.1720739 , -0.9006236 , -0.9855441 , -0.63783   ,\n",
       "       -0.60440123, -0.40759706, -0.5462128 , -0.7301471 , -0.6359313 ,\n",
       "       -0.59723246, -0.8217098 , -0.27621877, -0.72477764, -0.543077  ,\n",
       "       -0.94259757, -0.9994194 , -0.5546222 , -0.87402993, -0.57360226,\n",
       "       -0.69650984, -0.7625624 , -0.9986208 , -0.99847746, -0.6515042 ,\n",
       "       -0.9779214 , -0.720145  , -0.9991002 , -0.98966515, -0.9976332 ,\n",
       "       -0.9984395 , -0.99114865, -0.8211751 , -0.9198936 , -0.99720764,\n",
       "       -0.9996106 , -0.9970038 , -0.9854109 , -0.5989444 , -0.9770236 ,\n",
       "       -0.63506216, -0.9980963 ,  0.8896131 , -0.98915195, -0.9791757 ,\n",
       "       -0.9982359 , -0.55560815, -0.9422897 , -0.99720186, -0.9983309 ,\n",
       "       -0.5161595 , -0.47886336, -0.14158541, -0.98912424, -0.93046564,\n",
       "       -0.7258785 , -0.89212704, -0.8331303 , -0.99879074, -0.9966889 ,\n",
       "       -0.6538254 , -0.98796904, -0.8988873 , -0.99695855, -0.43551332,\n",
       "       -0.843322  , -0.99246925, -0.92569613, -0.9027776 , -0.9958635 ,\n",
       "       -0.98598766, -0.97477937, -0.99528474, -0.98886347, -0.96171284,\n",
       "       -0.916724  , -0.83973426, -0.62535715,  0.26921624, -0.97452015,\n",
       "       -0.7966224 , -0.9883142 , -0.98194003, -0.51745296, -0.7682119 ,\n",
       "       -0.96451384, -0.88127816, -0.5479802 , -0.914849  , -0.99800754,\n",
       "       -0.75125176, -0.7867398 ,  1.7357731 , -0.9059933 , -0.9922122 ,\n",
       "       -0.8902025 ,  0.26022285, -0.8795765 , -0.9803525 ,  0.77525586,\n",
       "       -0.99267656, -0.7388736 , -0.7486552 , -0.9785837 , -0.8660643 ,\n",
       "       -0.925124  , -0.8526172 ,  0.52839464, -0.71648437, -0.93644917,\n",
       "       -0.95044625, -0.9626275 , -0.98977464, -0.8697858 , -0.4959607 ,\n",
       "       -0.9717702 , -0.11935169, -0.8967348 , -0.84714776, -0.9980998 ,\n",
       "        1.326921  , -0.90071577, -0.73390305, -0.6849299 , -0.9345282 ,\n",
       "       -0.913664  , -0.69814813, -0.8389856 , -0.9961314 , -0.99854577,\n",
       "       -0.16162086, -0.9971641 , -0.9987252 , -0.9829737 , -0.5386126 ,\n",
       "       -0.4494214 , -0.8079426 , -0.9985627 , -0.9642583 , -0.99824643,\n",
       "       -0.95632356, -0.99767566, -0.82757145, -0.9713092 , -0.8972904 ,\n",
       "       -0.21820629, -0.9941511 , -0.97302973, -0.9926659 , -0.9990395 ,\n",
       "       -0.6598009 , -0.5383357 , -0.885975  , -0.9985514 , -0.87095   ,\n",
       "       -0.97856903, -0.99574256,  0.26998252, -0.8046801 , -0.98517007,\n",
       "       -0.28255534, -0.94171596, -0.8724048 , -0.99599755, -0.92294526,\n",
       "       -0.9750977 , -0.52120614, -0.92636245,  0.65800947, -0.9065478 ,\n",
       "       -0.8755292 , -0.9907887 , -0.8672256 , -0.26169848, -0.90324414,\n",
       "       -0.95199883, -0.95660204, -0.9699005 , -0.98346317, -0.9997352 ,\n",
       "       -0.9995676 , -0.99804604, -0.8433678 , -0.70252514, -0.7469726 ,\n",
       "       -0.99937326, -0.9999748 , -0.9989881 , -0.6842656 , -0.99531585,\n",
       "       -0.98579323, -0.9995859 , -0.9999684 , -0.98735094, -0.9998501 ,\n",
       "       -0.9997112 , -0.99952364, -0.9988119 , -0.99703   , -0.99744475,\n",
       "       -0.99984324, -0.875495  , -0.6824056 , -0.9996196 , -0.9756301 ,\n",
       "       -0.9984526 , -0.9999519 , -0.99925816, -0.99885005, -0.9998275 ,\n",
       "       -0.9997134 , -0.9991527 , -0.9999286 , -0.9997752 , -0.9987855 ,\n",
       "       -0.9997801 , -0.9997548 , -0.99956673, -0.9968906 , -0.99989796,\n",
       "       -0.99976796, -0.99907154, -0.9993423 , -0.9995766 , -0.99969757,\n",
       "       -0.9945594 , -0.9999012 , -0.9986695 , -0.99968886, -0.9997418 ,\n",
       "       -0.8687799 , -0.7243901 , -0.8539884 , -0.75637674, -0.9810708 ,\n",
       "       -0.9821999 , -0.8088794 , -0.97142565, -0.9540361 , -0.96423   ,\n",
       "        0.86931473, -0.26580667,  0.49863833, -0.62222713, -0.92897624,\n",
       "       -0.07802933,  0.8437695 , -0.94262534, -0.9818494 , -0.99420786,\n",
       "       -0.98303837, -0.96549803, -0.70540047, -0.7958429 , -0.7654213 ,\n",
       "       -0.6070812 , -0.9711093 , -0.6028533 , -0.45581353,  0.49082392,\n",
       "       -0.93930113, -0.70047957, -0.64378995, -0.9802675 , -0.77932394,\n",
       "       -0.7185161 , -0.990337  , -0.84257084,  0.63644046, -0.70461583,\n",
       "       -0.72802424, -0.99118304, -0.97100496, -0.93651396,  0.19994158,\n",
       "       -0.729921  , -0.71771204, -0.82132727, -0.97162265, -0.9985098 ,\n",
       "       -0.8389687 , -0.93125963, -0.49732095, -0.5732744 , -0.9912639 ,\n",
       "       -0.9637634 , -0.6791799 , -0.99940246, -0.5723002 , -0.71527755,\n",
       "       -0.5938642 , -0.875392  , -0.65467894, -0.9988247 , -0.7804965 ,\n",
       "       -0.50599575, -0.9070545 , -0.9965681 , -0.16571724, -0.7023696 ,\n",
       "       -0.5543349 , -0.5073533 , -0.41647124, -0.596195  , -0.7602514 ,\n",
       "       -0.68028295, -0.8708731 , -0.8828919 , -0.9991838 , -0.456522  ,\n",
       "       -0.98163235, -0.8494036 , -0.9991796 , -0.22264475, -0.5453295 ,\n",
       "       -0.7031321 , -0.94027025, -0.39675748, -0.6189413 , -0.85942215,\n",
       "       -0.28775656, -0.6167358 , -0.7403631 , -0.9977535 , -0.9525232 ,\n",
       "       -0.5536163 , -0.35899955, -0.56076205, -0.6225905 , -0.83752376,\n",
       "       -0.23218757, -0.24000812], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
